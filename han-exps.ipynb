{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ca094b3",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-04-07T04:41:24.877131Z",
     "iopub.status.busy": "2024-04-07T04:41:24.876742Z",
     "iopub.status.idle": "2024-04-07T04:41:24.883841Z",
     "shell.execute_reply": "2024-04-07T04:41:24.882762Z",
     "shell.execute_reply.started": "2024-04-07T04:41:24.877104Z"
    },
    "papermill": {
     "duration": 0.010384,
     "end_time": "2024-06-03T02:01:51.087059",
     "exception": false,
     "start_time": "2024-06-03T02:01:51.076675",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Hierarchical Attention Networks for Document Classification\n",
    "PyTorch implementation of **Hierarchical Attention Networks for Document Classification (NAACL 2016)**\n",
    "\n",
    "# Table of Contents\n",
    "* [Preamble](#Preamble)\n",
    "* [Word2Vec Module](#Word2Vec-Module)\n",
    "* [Load Vocabulary and Embeddings](#Load-Vocabulary-and-Embeddings)\n",
    "    * [Negative sampling](#Negative-sampling)\n",
    "    * [GloVe](#GloVe)\n",
    "* [PyTorch Dataset class](#PyTorch-Dataset-class)\n",
    "* [HAN Model](#HAN-Model)\n",
    "* [Training](#Training)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "833c9819",
   "metadata": {
    "papermill": {
     "duration": 0.01123,
     "end_time": "2024-06-03T02:01:51.110454",
     "exception": false,
     "start_time": "2024-06-03T02:01:51.099224",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Preamble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9878bbe6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-03T02:01:51.137873Z",
     "iopub.status.busy": "2024-06-03T02:01:51.136433Z",
     "iopub.status.idle": "2024-06-03T02:01:55.490909Z",
     "shell.execute_reply": "2024-06-03T02:01:55.489938Z"
    },
    "papermill": {
     "duration": 4.36989,
     "end_time": "2024-06-03T02:01:55.493302",
     "exception": false,
     "start_time": "2024-06-03T02:01:51.123412",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Preamble\n",
    "import time, random\n",
    "import re, string\n",
    "import os, sys\n",
    "import math\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a73b31e7",
   "metadata": {
    "papermill": {
     "duration": 0.008038,
     "end_time": "2024-06-03T02:01:55.509470",
     "exception": false,
     "start_time": "2024-06-03T02:01:55.501432",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Word2Vec Module\n",
    "Following the original paper, we trained the word embeddings using *Negative sampling* technique introduced in **Distributed Representations of Words and Phrases and their Compositionality (NIPS 2013)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a32c4251",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-03T02:01:55.526836Z",
     "iopub.status.busy": "2024-06-03T02:01:55.526399Z",
     "iopub.status.idle": "2024-06-03T02:01:55.537949Z",
     "shell.execute_reply": "2024-06-03T02:01:55.537137Z"
    },
    "papermill": {
     "duration": 0.02254,
     "end_time": "2024-06-03T02:01:55.539835",
     "exception": false,
     "start_time": "2024-06-03T02:01:55.517295",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Negative sampling embedding module\n",
    "class NegSamplingEmbedding(nn.Module):\n",
    "    '''\n",
    "    Vocab_size: V\n",
    "    Embedding_size: E\n",
    "    Text_length: L\n",
    "    Batch_size: B\n",
    "    \n",
    "    Consult: https://github.com/mindspore-courses/DeepNLP-models-MindSpore/\n",
    "            blob/main/notebooks/02.Skip-gram-Negative-Sampling.ipynb\n",
    "    '''\n",
    "    def __init__(self, vocab_size, embedding_size):\n",
    "        super(NegSamplingEmbedding, self).__init__()\n",
    "        self.U = nn.Embedding(vocab_size, embedding_size) # Center embedding\n",
    "        self.V = nn.Embedding(vocab_size, embedding_size) # Outside embedding\n",
    "        self.LogSig = nn.LogSigmoid()\n",
    "        \n",
    "    def forward(self, wc, wo, wk, mask_c, mask_o, check_shape= False):\n",
    "        vc = self.V(wc) # Center embedding. Shape: (B, L, E)\n",
    "        uo = self.U(wo) # Outside embedding. Shape: (B, L, C, E)\n",
    "        uk = self.U(wk) # Random embedding. Shape: (B, L, C, E, K)\n",
    "        \n",
    "        if check_shape:\n",
    "            B = uk.shape[0]\n",
    "            L = uk.shape[1]\n",
    "            C = uk.shape[2]\n",
    "            K = uk.shape[3]\n",
    "            E = uk.shape[4]\n",
    "            print(f\"Basic shapes: B = {B}; L = {L}; C = {C}; K = {K}; E = {E}\")\n",
    "            print('*********************************')\n",
    "            print('Shape of vc:', vc.shape)\n",
    "            print('Shape of uo:', uo.shape)\n",
    "            print('Shape of uk:', uk.shape)\n",
    "            print('*********************************')\n",
    "        cmp1 = torch.einsum('blce,ble->blc', uo, vc) # Shape: (B, L, C)\n",
    "        cmp2 = torch.einsum('blcke,ble->blck', uk, vc) # Shape: (B, L, C, K)\n",
    "        \n",
    "        cmp1 = self.LogSig(cmp1) * mask_o # Shape: (B, L, C)\n",
    "        cmp2 = self.LogSig(-cmp2) # Shape: (B, L, C, K)\n",
    "        cmp2 = torch.einsum('blck->blc', cmp2) * mask_o # Shape: (B, L, C)\n",
    "    \n",
    "        cmp1 = torch.einsum('blc->bl', cmp1) # Shape: (B, L)\n",
    "        cmp2 = torch.einsum('blc->bl', cmp2) # Shape: (B, L)\n",
    "        \n",
    "        loss = torch.mean(cmp1 + cmp2)\n",
    "        \n",
    "        if check_shape:\n",
    "            print('Shape of cmp1:', cmp1.shape)\n",
    "            print('Shape of cmp2:', cmp2.shape)\n",
    "            print('Shape of LOSS:', loss.shape)\n",
    "        return -loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ed53fee",
   "metadata": {
    "papermill": {
     "duration": 0.008512,
     "end_time": "2024-06-03T02:01:55.556050",
     "exception": false,
     "start_time": "2024-06-03T02:01:55.547538",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Load Vocabulary and Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e662fe3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-03T02:01:55.572456Z",
     "iopub.status.busy": "2024-06-03T02:01:55.572187Z",
     "iopub.status.idle": "2024-06-03T02:01:55.575753Z",
     "shell.execute_reply": "2024-06-03T02:01:55.574920Z"
    },
    "papermill": {
     "duration": 0.013794,
     "end_time": "2024-06-03T02:01:55.577542",
     "exception": false,
     "start_time": "2024-06-03T02:01:55.563748",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Embedding type. 'glove' or 'negative_sampling'\n",
    "MODE = 'glove'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85ba5934",
   "metadata": {
    "papermill": {
     "duration": 0.007626,
     "end_time": "2024-06-03T02:01:55.592946",
     "exception": false,
     "start_time": "2024-06-03T02:01:55.585320",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Negative sampling\n",
    "Here we load the pretrained vocab and embeddings constructed using **Negative Sampling.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec3136b7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-03T02:01:55.609353Z",
     "iopub.status.busy": "2024-06-03T02:01:55.609075Z",
     "iopub.status.idle": "2024-06-03T02:01:57.189301Z",
     "shell.execute_reply": "2024-06-03T02:01:57.188473Z"
    },
    "papermill": {
     "duration": 1.591043,
     "end_time": "2024-06-03T02:01:57.191645",
     "exception": false,
     "start_time": "2024-06-03T02:01:55.600602",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Prepare vocab, counter, tokenizer\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import vocab, build_vocab_from_iterator\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "tokenizer = get_tokenizer(\"basic_english\")\n",
    "\n",
    "vocab_ns = torch.load('/kaggle/input/hlt-word2vec/vocab.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a7c689a5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-03T02:01:57.209747Z",
     "iopub.status.busy": "2024-06-03T02:01:57.208846Z",
     "iopub.status.idle": "2024-06-03T02:01:57.214329Z",
     "shell.execute_reply": "2024-06-03T02:01:57.213522Z"
    },
    "papermill": {
     "duration": 0.016221,
     "end_time": "2024-06-03T02:01:57.216167",
     "exception": false,
     "start_time": "2024-06-03T02:01:57.199946",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Task configs\n",
    "VOCAB_SIZE = len(vocab_ns)\n",
    "GRU_DIM = 50\n",
    "NUM_CLASSES = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa010d04",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-03T02:01:57.232490Z",
     "iopub.status.busy": "2024-06-03T02:01:57.232234Z",
     "iopub.status.idle": "2024-06-03T02:01:58.836085Z",
     "shell.execute_reply": "2024-06-03T02:01:58.835236Z"
    },
    "papermill": {
     "duration": 1.614402,
     "end_time": "2024-06-03T02:01:58.838268",
     "exception": false,
     "start_time": "2024-06-03T02:01:57.223866",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Prepare word embeddings\n",
    "WORD2VEC_PATH = '/kaggle/input/hlt-word2vec/word2vec.pth'\n",
    "EMBEDDING_DIM = 200\n",
    "word2vec = NegSamplingEmbedding(VOCAB_SIZE, EMBEDDING_DIM)\n",
    "word2vec.load_state_dict(torch.load(WORD2VEC_PATH, map_location= DEVICE))\n",
    "word2vec.eval()\n",
    "\n",
    "W_e = word2vec.V.weight.detach().to(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "010ae276",
   "metadata": {
    "papermill": {
     "duration": 0.007595,
     "end_time": "2024-06-03T02:01:58.854081",
     "exception": false,
     "start_time": "2024-06-03T02:01:58.846486",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## GloVe\n",
    "Here we import pretrained word embeddings **GloVe**. We plan on evaluating HAN using GloVe 6B $(D = 200)$ and GloVe 42B $(D = 300)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2075587b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-03T02:01:58.870779Z",
     "iopub.status.busy": "2024-06-03T02:01:58.870464Z",
     "iopub.status.idle": "2024-06-03T02:01:58.875637Z",
     "shell.execute_reply": "2024-06-03T02:01:58.874729Z"
    },
    "papermill": {
     "duration": 0.015864,
     "end_time": "2024-06-03T02:01:58.877614",
     "exception": false,
     "start_time": "2024-06-03T02:01:58.861750",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Double check vocab - embedding matching\n",
    "def arr_equal_check(arr1, arr2):\n",
    "    if len(arr1) != len(arr2):\n",
    "        return False\n",
    "    \n",
    "    for i in range(len(arr1)):\n",
    "        if arr1[i] != arr2[i]:\n",
    "            return False\n",
    "        \n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5cd9d123",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-03T02:01:58.895192Z",
     "iopub.status.busy": "2024-06-03T02:01:58.894904Z",
     "iopub.status.idle": "2024-06-03T02:06:03.952343Z",
     "shell.execute_reply": "2024-06-03T02:06:03.943470Z"
    },
    "papermill": {
     "duration": 245.069307,
     "end_time": "2024-06-03T02:06:03.955225",
     "exception": false,
     "start_time": "2024-06-03T02:01:58.885918",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load GloVe embeddings\n",
    "EMBEDDING_DIM = 300\n",
    "\n",
    "glove_txt = '/kaggle/input/glovewordembeddings/glove.42B.300d.txt'\n",
    "with open(glove_txt, 'r') as file:\n",
    "    lines = file.readlines()\n",
    "    file.close()\n",
    "\n",
    "W_list = []\n",
    "word_list = ['<unk>']\n",
    "freq = {} # Construct vocab from dict \n",
    "\n",
    "for line in lines:\n",
    "    words = line.split(' ')\n",
    "    word = words[0]\n",
    "    word_list.append(word)\n",
    "    freq[word] = 1\n",
    "    \n",
    "    arr = np.array(words[1:], dtype= float)\n",
    "    W_list.append(torch.tensor(arr, dtype= torch.float))\n",
    "    \n",
    "unk_embed = [sum(W_list) / len(W_list)]\n",
    "W_list = unk_embed + W_list\n",
    "\n",
    "W_glove = torch.stack(W_list).to(DEVICE)\n",
    "vocab_glove = vocab(\n",
    "    freq,\n",
    "    specials= [\"<unk>\"]\n",
    ")\n",
    "vocab_glove.set_default_index(vocab_glove[\"<unk>\"])\n",
    "\n",
    "# Make sure vocab match word embeddings\n",
    "assert arr_equal_check(vocab_glove.get_itos(), word_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a890ed00",
   "metadata": {
    "papermill": {
     "duration": 0.007562,
     "end_time": "2024-06-03T02:06:03.970895",
     "exception": false,
     "start_time": "2024-06-03T02:06:03.963333",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# PyTorch Dataset class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5925f2ff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-03T02:06:03.987820Z",
     "iopub.status.busy": "2024-06-03T02:06:03.987233Z",
     "iopub.status.idle": "2024-06-03T02:06:04.040411Z",
     "shell.execute_reply": "2024-06-03T02:06:04.039554Z"
    },
    "papermill": {
     "duration": 0.063808,
     "end_time": "2024-06-03T02:06:04.042305",
     "exception": false,
     "start_time": "2024-06-03T02:06:03.978497",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# YELP Dataset\n",
    "def collate_batch(batch):\n",
    "    '''\n",
    "    Collate batch with zero-padding\n",
    "    Consult: https://pytorch.org/tutorials/beginner/text_sentiment_ngrams_tutorial.html\n",
    "    '''\n",
    "    texts = []\n",
    "    labels = []\n",
    "    mask = []\n",
    "    for _text, _label in batch:\n",
    "        texts.append(_text)\n",
    "        labels.append(_label)\n",
    "        \n",
    "    L = max([len(text) for text in texts])\n",
    "    \n",
    "    for i in range(len(texts)):\n",
    "        l = texts[i].shape[0]\n",
    "        cur_mask = torch.ones(L)\n",
    "        if l < L:\n",
    "            cur_mask[l:L] = 0\n",
    "            # Zero-padding text, only on one side.\n",
    "            texts[i] = F.pad(texts[i], (0, L-l), 'constant', 0)\n",
    "            \n",
    "        mask.append(cur_mask)\n",
    "    \n",
    "    texts = torch.stack(texts)\n",
    "    labels = torch.stack(labels)\n",
    "    mask = torch.stack(mask)\n",
    "    return texts, labels, mask\n",
    "\n",
    "def collate_batch_HAN(batch):\n",
    "    return batch\n",
    "\n",
    "class NLPDataset(Dataset):\n",
    "    def __init__(self, df, vocab, tokenizer, \n",
    "                 text_col= 'text', label_col= 'label',\n",
    "                 df_sort= True, punct_splt= False):\n",
    "        self.df = df\n",
    "        self.tokenizer = tokenizer\n",
    "        self.vocab = vocab\n",
    "        self.len_vocab = len(vocab)\n",
    "        self.punct_splt = punct_splt\n",
    "        if df_sort:\n",
    "            self.sort_df_by_txt_len(text_col)\n",
    "        self.fea = text_col\n",
    "        self.label = label_col\n",
    "    \n",
    "    def sort_df_by_txt_len(self, text_col):\n",
    "        len_list = [-len(re.split(\"[.!?]+\", self.df.iloc[i][text_col])) for i in range(len(self.df))]\n",
    "        self.df = self.df.iloc[np.argsort(len_list)]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def text_pipeline(self, x):\n",
    "        x = x.replace('\\'', '')\n",
    "        return self.vocab(self.tokenizer(x))\n",
    "\n",
    "    def label_pipeline(self, x):\n",
    "        return int(x)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if not self.punct_splt:\n",
    "            txt = self.text_pipeline(self.df.iloc[idx][self.fea])\n",
    "            txt = torch.tensor(txt, dtype= torch.int64)\n",
    "\n",
    "            label = self.label_pipeline(self.df.iloc[idx][self.label])\n",
    "            label = torch.tensor(label, dtype= torch.int64)\n",
    "\n",
    "            return (txt, label)\n",
    "    \n",
    "        else:\n",
    "            txt = self.df.iloc[idx][self.fea]\n",
    "            sentences = re.split(\"[.!?]+\", txt)\n",
    "            L = 0\n",
    "            X = []\n",
    "            mask = []\n",
    "            \n",
    "            for s in sentences:\n",
    "                l = len(s)\n",
    "                if l == 0:\n",
    "                    continue\n",
    "                X.append(torch.tensor(self.text_pipeline(s), dtype= torch.int64))\n",
    "                L = max(L, X[-1].shape[0])\n",
    "                \n",
    "            if len(X) == 0:\n",
    "                return (None, None, None)\n",
    "            \n",
    "            for i in range(len(X)):\n",
    "                l = X[i].shape[0]\n",
    "                cur_mask = torch.ones(L)\n",
    "                \n",
    "                # Zero-padding sentence\n",
    "                if(l < L):\n",
    "                    # Zero-padding sentence, only on one side.\n",
    "                    X[i] = F.pad(X[i], (0, L - l), 'constant', 0)\n",
    "                    cur_mask[l:L] = 0\n",
    "                \n",
    "                mask.append(cur_mask)\n",
    "                    \n",
    "            X = torch.stack(X)\n",
    "            mask = torch.stack(mask)\n",
    "            \n",
    "            label = self.label_pipeline(self.df.iloc[idx][self.label])\n",
    "            label = torch.tensor(label, dtype= torch.int64)\n",
    "            \n",
    "            return (X, label, mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "363ea7d8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-03T02:06:04.058975Z",
     "iopub.status.busy": "2024-06-03T02:06:04.058682Z",
     "iopub.status.idle": "2024-06-03T02:06:04.119032Z",
     "shell.execute_reply": "2024-06-03T02:06:04.118089Z"
    },
    "papermill": {
     "duration": 0.071094,
     "end_time": "2024-06-03T02:06:04.121202",
     "exception": false,
     "start_time": "2024-06-03T02:06:04.050108",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # YELP preparation\n",
    "# data_file = open(\"/kaggle/input/yelp-dataset/yelp_academic_dataset_review.json\")\n",
    "# data = []\n",
    "\n",
    "# # cnt = 1569264 # Size of YELP 2015 dataset\n",
    "# cnt = 10000\n",
    "\n",
    "# for line in data_file:\n",
    "#     data.append(json.loads(line))\n",
    "#     cnt -= 1\n",
    "#     if cnt == 0:\n",
    "#         break\n",
    "    \n",
    "# data_file.close()\n",
    "# df = pd.DataFrame(data)\n",
    "\n",
    "# print(\"Number of datapoints:\", len(df))\n",
    "# df.head()\n",
    "\n",
    "# # R52 Preparation\n",
    "# train_df = pd.read_csv('/kaggle/input/smolcsv/r52-train-stemmed.csv')\n",
    "# val_df = pd.read_csv('/kaggle/input/smolcsv/r52-dev-stemmed.csv')\n",
    "# test_df = pd.read_csv('/kaggle/input/smolcsv/r52-test-stemmed.csv')\n",
    "\n",
    "# df = pd.concat([train_df, val_df, test_df])\n",
    "\n",
    "# print('Size of data corpus:', len(df))\n",
    "# df.head()\n",
    "\n",
    "# MR Preparation\n",
    "df = pd.read_csv('/kaggle/input/smolcsv/MR.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aa3513a0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-03T02:06:04.138821Z",
     "iopub.status.busy": "2024-06-03T02:06:04.138252Z",
     "iopub.status.idle": "2024-06-03T02:06:04.160826Z",
     "shell.execute_reply": "2024-06-03T02:06:04.159773Z"
    },
    "papermill": {
     "duration": 0.033308,
     "end_time": "2024-06-03T02:06:04.162894",
     "exception": false,
     "start_time": "2024-06-03T02:06:04.129586",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of trainset: 8529\n",
      "Size of valset: 1066\n",
      "Size of testset: 1067\n"
     ]
    }
   ],
   "source": [
    "# Train-val-test splits\n",
    "df_size = len(df)\n",
    "idx = [x for x in range(df_size)]\n",
    "random.Random(555).shuffle(idx)\n",
    "\n",
    "train_num = int(df_size * 0.8)\n",
    "val_num = int(df_size * 0.1)\n",
    "test_num = int(df_size * 0.1)\n",
    "\n",
    "# print(train_num, val_num, test_num)\n",
    "\n",
    "train_idx = idx[:train_num]\n",
    "val_idx = idx[train_num : (train_num + val_num)]\n",
    "test_idx = idx[(train_num + val_num) : ]\n",
    "\n",
    "train_df = df.iloc[train_idx]\n",
    "val_df = df.iloc[val_idx]\n",
    "test_df = df.iloc[test_idx]\n",
    "\n",
    "print('Size of trainset:', len(train_df))\n",
    "print('Size of valset:', len(val_df))\n",
    "print('Size of testset:', len(test_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c19d3e5a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-03T02:06:04.180291Z",
     "iopub.status.busy": "2024-06-03T02:06:04.179641Z",
     "iopub.status.idle": "2024-06-03T02:06:04.910371Z",
     "shell.execute_reply": "2024-06-03T02:06:04.909392Z"
    },
    "papermill": {
     "duration": 0.741478,
     "end_time": "2024-06-03T02:06:04.912436",
     "exception": false,
     "start_time": "2024-06-03T02:06:04.170958",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Texts: torch.Size([13, 19])\n",
      "Shape of Labels: torch.Size([])\n",
      "Shape of Mask: torch.Size([13, 19])\n"
     ]
    }
   ],
   "source": [
    "# Dataset, Dataloader\n",
    "if MODE == 'glove':\n",
    "    data_vocab = vocab_glove\n",
    "if MODE == 'negative_sampling':\n",
    "    data_vocab = vocab_ns\n",
    "\n",
    "trainset = NLPDataset(train_df, data_vocab, tokenizer, punct_splt= True)\n",
    "valset = NLPDataset(val_df, data_vocab, tokenizer, punct_splt= True)\n",
    "testset = NLPDataset(test_df, data_vocab, tokenizer, punct_splt= True)\n",
    "\n",
    "trainloader = DataLoader(trainset, batch_size= BATCH_SIZE, \n",
    "                         shuffle= False, pin_memory= True, collate_fn= collate_batch_HAN)\n",
    "valloader = DataLoader(valset, batch_size= BATCH_SIZE, \n",
    "                         shuffle= False, pin_memory= True, collate_fn= collate_batch_HAN)\n",
    "testloader = DataLoader(testset, batch_size= BATCH_SIZE, \n",
    "                         shuffle= False, pin_memory= True, collate_fn= collate_batch_HAN)\n",
    "\n",
    "for batch in trainloader:\n",
    "    X, y, mask = batch[0]\n",
    "    print(\"Shape of Texts:\", X.shape)\n",
    "    print(\"Shape of Labels:\", y.shape)\n",
    "    print(\"Shape of Mask:\", mask.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fdbfe50",
   "metadata": {
    "papermill": {
     "duration": 0.007679,
     "end_time": "2024-06-03T02:06:04.928169",
     "exception": false,
     "start_time": "2024-06-03T02:06:04.920490",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# HAN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c230c77f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-03T02:06:04.945346Z",
     "iopub.status.busy": "2024-06-03T02:06:04.944710Z",
     "iopub.status.idle": "2024-06-03T02:06:04.960103Z",
     "shell.execute_reply": "2024-06-03T02:06:04.959407Z"
    },
    "papermill": {
     "duration": 0.025976,
     "end_time": "2024-06-03T02:06:04.961922",
     "exception": false,
     "start_time": "2024-06-03T02:06:04.935946",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class HANModel(nn.Module):\n",
    "    def __init__(self, W_e, embedding_dim, gru_dim, \n",
    "                 num_classes):\n",
    "        super(HANModel, self).__init__()\n",
    "        \n",
    "        DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "        \n",
    "        # Initialize\n",
    "        self.E = embedding_dim\n",
    "        self.G = gru_dim\n",
    "        self.num_classes = num_classes\n",
    "        \n",
    "        # Pretrained word embeddings\n",
    "        self.W_e = W_e\n",
    "        \n",
    "        # Word-level attention\n",
    "        self.WordEncoder = nn.GRU(\n",
    "            input_size= embedding_dim,\n",
    "            hidden_size= gru_dim,\n",
    "            batch_first= True,\n",
    "            bidirectional= True\n",
    "        )\n",
    "        self.WordMLP = nn.Sequential(\n",
    "            nn.Linear(2*gru_dim, 2*gru_dim),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        self.u_w = nn.Parameter(torch.randn(2*gru_dim))\n",
    "        \n",
    "        # Sequence-level attention\n",
    "        self.SeqEncoder = nn.GRU(\n",
    "            input_size= 2*gru_dim,\n",
    "            hidden_size= gru_dim,\n",
    "            batch_first= True,\n",
    "            bidirectional= True\n",
    "        )\n",
    "        self.SeqMLP = nn.Sequential(\n",
    "            nn.Linear(2*gru_dim, 2*gru_dim),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        self.u_s = nn.Parameter(torch.randn(2*gru_dim))\n",
    "        \n",
    "        # Classifier\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(2*gru_dim, num_classes),\n",
    "            nn.Softmax()\n",
    "        )\n",
    "        \n",
    "    def forward(self, text, mask, check_shape= False):\n",
    "        '''\n",
    "        <text> is expected to have shape (S, L)\n",
    "        \n",
    "        Number of sentence: S\n",
    "        Max sentence length: L\n",
    "        Embedding size: E\n",
    "        GRU dimension: G -> Bidirectional: 2G\n",
    "        '''\n",
    "        S = text.shape[0]\n",
    "        L = text.shape[1]\n",
    "        \n",
    "        x = self.W_e[text] # Text embedding, Shape: (S, L, E)\n",
    "        hW,_ = self.WordEncoder(x) # Word annotation. Shape: (S, L, 2G)\n",
    "        uW = self.WordMLP(hW) # Word hidden representation. Shape: (S, L, 2G)\n",
    "\n",
    "        # Attention weight - Needs verifications\n",
    "        alphaW = nn.Softmax()(torch.einsum('slg,g->sl', uW, self.u_w) * mask) # Shape: (S, L)\n",
    "        \n",
    "        # Sentence vector\n",
    "        s = torch.einsum('slg,sl->sg', hW, alphaW) # Shape: (S, 2G)\n",
    "        hS,_ = self.SeqEncoder(s) # Sentence annotation. Shape: (S, 2G)\n",
    "        uS = self.SeqMLP(hS) # Sentence hidden representation. Shape: (S, 2G)\n",
    "        \n",
    "        # Attention weight - Needs verifications\n",
    "        alphaS = nn.Softmax()(torch.matmul(uS, self.u_s)) # Shape: (S)\n",
    "        \n",
    "        # Document vector\n",
    "        v = torch.matmul(alphaS, hS)\n",
    "        \n",
    "        logits = self.classifier(v)\n",
    "        \n",
    "        if check_shape:\n",
    "            print(f'Basic shapes: S = {S}, E = {self.E}, L = {L}, G = {self.G}')\n",
    "            print('*********************************')\n",
    "            print('Shape of x:', x.shape)\n",
    "            print('Shape of hW:', hW.shape)\n",
    "            print('Shape of uW:', uW.shape)\n",
    "            print('Shape of alphaW:', alphaW.shape)\n",
    "            print('*********************************')\n",
    "            print('Shape of s:', s.shape)\n",
    "            print('Shape of hS:', hS.shape)\n",
    "            print('Shape of uS:', uS.shape)\n",
    "            print('Shape of alphaS:', alphaS.shape)\n",
    "            print('*********************************')\n",
    "            print('Shape of v:', v.shape)\n",
    "            print('Shape of logits:', logits.shape)\n",
    "        \n",
    "        return logits\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "84f0bb4a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-03T02:06:04.978903Z",
     "iopub.status.busy": "2024-06-03T02:06:04.978383Z",
     "iopub.status.idle": "2024-06-03T02:06:04.982738Z",
     "shell.execute_reply": "2024-06-03T02:06:04.981920Z"
    },
    "papermill": {
     "duration": 0.014581,
     "end_time": "2024-06-03T02:06:04.984484",
     "exception": false,
     "start_time": "2024-06-03T02:06:04.969903",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Xavier normal initialization\n",
    "def xavier_normal_init(m):\n",
    "    '''\n",
    "    Xavier normal initialization.\n",
    "    '''\n",
    "    if type(m) == nn.Linear or type(m) == nn.Parameter:\n",
    "        print(m)\n",
    "        torch.nn.init.xavier_normal_(m.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5b15bbfe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-03T02:06:05.001059Z",
     "iopub.status.busy": "2024-06-03T02:06:05.000828Z",
     "iopub.status.idle": "2024-06-03T02:06:05.490450Z",
     "shell.execute_reply": "2024-06-03T02:06:05.489568Z"
    },
    "papermill": {
     "duration": 0.501102,
     "end_time": "2024-06-03T02:06:05.493329",
     "exception": false,
     "start_time": "2024-06-03T02:06:04.992227",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********************************\n",
      "Submodules having Xavier normal initialization:\n",
      "Linear(in_features=100, out_features=100, bias=True)\n",
      "Linear(in_features=100, out_features=100, bias=True)\n",
      "Linear(in_features=100, out_features=2, bias=True)\n",
      "*********************************\n",
      "Basic shapes: S = 13, E = 300, L = 19, G = 50\n",
      "*********************************\n",
      "Shape of x: torch.Size([13, 19, 300])\n",
      "Shape of hW: torch.Size([13, 19, 100])\n",
      "Shape of uW: torch.Size([13, 19, 100])\n",
      "Shape of alphaW: torch.Size([13, 19])\n",
      "*********************************\n",
      "Shape of s: torch.Size([13, 100])\n",
      "Shape of hS: torch.Size([13, 100])\n",
      "Shape of uS: torch.Size([13, 100])\n",
      "Shape of alphaS: torch.Size([13])\n",
      "*********************************\n",
      "Shape of v: torch.Size([100])\n",
      "Shape of logits: torch.Size([2])\n",
      "*********************************\n",
      "HANModel(\n",
      "  (WordEncoder): GRU(300, 50, batch_first=True, bidirectional=True)\n",
      "  (WordMLP): Sequential(\n",
      "    (0): Linear(in_features=100, out_features=100, bias=True)\n",
      "    (1): Tanh()\n",
      "  )\n",
      "  (SeqEncoder): GRU(100, 50, batch_first=True, bidirectional=True)\n",
      "  (SeqMLP): Sequential(\n",
      "    (0): Linear(in_features=100, out_features=100, bias=True)\n",
      "    (1): Tanh()\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=100, out_features=2, bias=True)\n",
      "    (1): Softmax(dim=None)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self._call_impl(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "model = HANModel(W_glove, EMBEDDING_DIM, GRU_DIM, NUM_CLASSES).to(DEVICE)\n",
    "print('*********************************')\n",
    "print('Submodules having Xavier normal initialization:')\n",
    "model.apply(xavier_normal_init)\n",
    "print('*********************************')\n",
    "\n",
    "for batch in trainloader:\n",
    "    X, y, mask = batch[0]\n",
    "    X, mask = X.to(DEVICE), mask.to(DEVICE)\n",
    "    logits = model(X, mask, check_shape= True)\n",
    "    break\n",
    "    \n",
    "print('*********************************')\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "254d8938",
   "metadata": {
    "papermill": {
     "duration": 0.008117,
     "end_time": "2024-06-03T02:06:05.509846",
     "exception": false,
     "start_time": "2024-06-03T02:06:05.501729",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d9a104a4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-03T02:06:05.527121Z",
     "iopub.status.busy": "2024-06-03T02:06:05.526811Z",
     "iopub.status.idle": "2024-06-03T02:06:07.243882Z",
     "shell.execute_reply": "2024-06-03T02:06:07.243063Z"
    },
    "papermill": {
     "duration": 1.728189,
     "end_time": "2024-06-03T02:06:07.246075",
     "exception": false,
     "start_time": "2024-06-03T02:06:05.517886",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Training configs\n",
    "LR = 1e-3\n",
    "MOMENTUM = 0.9\n",
    "EPOCHS = 40\n",
    "ITER = EPOCHS * len(trainloader)\n",
    "OPTIMIZER = torch.optim.Adam(model.parameters(), lr= LR)\n",
    "# OPTIMIZER = torch.optim.SGD(model.parameters(), lr= LR, momentum= MOMENTUM, nesterov= True)\n",
    "SCHEDULER = lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(OPTIMIZER, T_max = ITER)\n",
    "LOSS_FN = nn.CrossEntropyLoss()\n",
    "RECORD = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3af1cda9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-03T02:06:07.264318Z",
     "iopub.status.busy": "2024-06-03T02:06:07.263874Z",
     "iopub.status.idle": "2024-06-03T02:06:07.278884Z",
     "shell.execute_reply": "2024-06-03T02:06:07.278066Z"
    },
    "papermill": {
     "duration": 0.026101,
     "end_time": "2024-06-03T02:06:07.280713",
     "exception": false,
     "start_time": "2024-06-03T02:06:07.254612",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Train procedures\n",
    "def test(testloader, model, loss_fn):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    bcnt = 0\n",
    "    cnt = 0\n",
    "    \n",
    "    for i, batch in enumerate(testloader):\n",
    "        tmp_loss = 0\n",
    "        cnt += 1\n",
    "        for (X, y, mask) in batch:\n",
    "            if X is None:\n",
    "                continue\n",
    "            bcnt += 1\n",
    "            X, y, mask = X.to(DEVICE), y.to(DEVICE), mask.to(DEVICE)\n",
    "            pred = model(X, mask)\n",
    "            tmp_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(0) == y).type(torch.float).sum().item()\n",
    "        tmp_loss /= len(batch)\n",
    "        test_loss += tmp_loss\n",
    "        \n",
    "    test_loss /= len(testloader)\n",
    "    accuracy = correct / len(testloader.dataset)\n",
    "    \n",
    "    return test_loss, accuracy\n",
    "\n",
    "def train(trainloader, valloader, model, optimizer, scheduler, loss_fn, val_freq):\n",
    "    global RECORD\n",
    "    model.train()\n",
    "    tloss = []\n",
    "    cur_acc = 0\n",
    "    for i, batch in enumerate(trainloader):\n",
    "        loss = 0\n",
    "        for (X, y, mask) in batch:\n",
    "            if X is None:\n",
    "                continue\n",
    "            X, y, mask = X.to(DEVICE), y.to(DEVICE), mask.to(DEVICE)\n",
    "            logits = model(X, mask)\n",
    "            loss += loss_fn(logits, y)\n",
    "        loss /= len(batch)\n",
    "        \n",
    "        if val_freq > 0 and i % val_freq == 0:\n",
    "            tloss.append(loss.cpu().detach().numpy())\n",
    "            model.eval()\n",
    "            val_loss, val_acc = test(valloader, model, loss_fn)\n",
    "            model.train()\n",
    "            print(f'Iter {i}, loss = {tloss[-1]}, val_acc = {val_acc}')\n",
    "            if RECORD < val_acc:\n",
    "                RECORD = val_acc\n",
    "                print('Saving model...')\n",
    "                torch.save(model.state_dict(), f'HAN_{val_acc*100}.pth')\n",
    "                torch.save(model.state_dict(), f'HAN_best.pth')\n",
    "        \n",
    "        tloss.append(loss.cpu().detach().numpy())\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "#         scheduler.step()\n",
    "        \n",
    "    model.eval()\n",
    "    val_loss, val_acc = test(valloader, model, loss_fn)\n",
    "    model.train()\n",
    "    print(f'Iter {i}, loss = {tloss[-1]}, val_acc = {val_acc}')\n",
    "    if RECORD < val_acc:\n",
    "        RECORD = val_acc\n",
    "        print('Saving model...')\n",
    "        torch.save(model.state_dict(), f'HAN_{val_acc*100}.pth')\n",
    "        torch.save(model.state_dict(), f'HAN_best.pth')\n",
    "        \n",
    "    return tloss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fac85df2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-03T02:06:07.297812Z",
     "iopub.status.busy": "2024-06-03T02:06:07.297554Z",
     "iopub.status.idle": "2024-06-03T02:34:07.808398Z",
     "shell.execute_reply": "2024-06-03T02:34:07.807569Z"
    },
    "papermill": {
     "duration": 1680.521703,
     "end_time": "2024-06-03T02:34:07.810460",
     "exception": false,
     "start_time": "2024-06-03T02:06:07.288757",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 starts.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self._call_impl(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 0, loss = 0.701049268245697, val_acc = 0.4971857410881801\n",
      "Saving model...\n",
      "Iter 50, loss = 0.598972737789154, val_acc = 0.6894934333958724\n",
      "Saving model...\n",
      "Iter 100, loss = 0.586572527885437, val_acc = 0.7195121951219512\n",
      "Saving model...\n",
      "Iter 133, loss = 0.561438262462616, val_acc = 0.7326454033771107\n",
      "Saving model...\n",
      "Epoch 0: LOSS = 0.6055139466358798, VAL-ACC = 0.7326454033771107\n",
      "Epoch 1 starts.\n",
      "Iter 0, loss = 0.543951690196991, val_acc = 0.7326454033771107\n",
      "Iter 50, loss = 0.5962928533554077, val_acc = 0.7373358348968105\n",
      "Saving model...\n",
      "Iter 100, loss = 0.5421854853630066, val_acc = 0.7354596622889306\n",
      "Iter 133, loss = 0.4812784790992737, val_acc = 0.7664165103189493\n",
      "Saving model...\n",
      "Epoch 1: LOSS = 0.5393959618832943, VAL-ACC = 0.7664165103189493\n",
      "Epoch 2 starts.\n",
      "Iter 0, loss = 0.4477243721485138, val_acc = 0.7664165103189493\n",
      "Iter 50, loss = 0.5097915530204773, val_acc = 0.7720450281425891\n",
      "Saving model...\n",
      "Iter 100, loss = 0.5046555995941162, val_acc = 0.7429643527204502\n",
      "Iter 133, loss = 0.42232030630111694, val_acc = 0.7617260787992496\n",
      "Epoch 2: LOSS = 0.5043056011199951, VAL-ACC = 0.7617260787992496\n",
      "Epoch 3 starts.\n",
      "Iter 0, loss = 0.46001800894737244, val_acc = 0.7617260787992496\n",
      "Iter 50, loss = 0.48215746879577637, val_acc = 0.7692307692307693\n",
      "Iter 100, loss = 0.4783267080783844, val_acc = 0.776735459662289\n",
      "Saving model...\n",
      "Iter 133, loss = 0.4367285370826721, val_acc = 0.773921200750469\n",
      "Epoch 3: LOSS = 0.4961392783770596, VAL-ACC = 0.773921200750469\n",
      "Epoch 4 starts.\n",
      "Iter 0, loss = 0.4651488959789276, val_acc = 0.773921200750469\n",
      "Iter 50, loss = 0.47267961502075195, val_acc = 0.7786116322701688\n",
      "Saving model...\n",
      "Iter 100, loss = 0.46198898553848267, val_acc = 0.7786116322701688\n",
      "Iter 133, loss = 0.4332651197910309, val_acc = 0.7964352720450282\n",
      "Saving model...\n",
      "Epoch 4: LOSS = 0.48241373679063615, VAL-ACC = 0.7964352720450282\n",
      "Epoch 5 starts.\n",
      "Iter 0, loss = 0.43850386142730713, val_acc = 0.7964352720450282\n",
      "Iter 50, loss = 0.4551227390766144, val_acc = 0.7673545966228893\n",
      "Iter 100, loss = 0.4530630111694336, val_acc = 0.7617260787992496\n",
      "Iter 133, loss = 0.3803853690624237, val_acc = 0.776735459662289\n",
      "Epoch 5: LOSS = 0.4723352787703493, VAL-ACC = 0.776735459662289\n",
      "Epoch 6 starts.\n",
      "Iter 0, loss = 0.43336889147758484, val_acc = 0.776735459662289\n",
      "Iter 50, loss = 0.47172072529792786, val_acc = 0.7729831144465291\n",
      "Iter 100, loss = 0.48780760169029236, val_acc = 0.7729831144465291\n",
      "Iter 133, loss = 0.3951680362224579, val_acc = 0.7589118198874296\n",
      "Epoch 6: LOSS = 0.45593200439084186, VAL-ACC = 0.7589118198874296\n",
      "Epoch 7 starts.\n",
      "Iter 0, loss = 0.5212092995643616, val_acc = 0.7589118198874296\n",
      "Iter 50, loss = 0.48408976197242737, val_acc = 0.7701688555347092\n",
      "Iter 100, loss = 0.49463343620300293, val_acc = 0.7598499061913696\n",
      "Iter 133, loss = 0.3847150206565857, val_acc = 0.7589118198874296\n",
      "Epoch 7: LOSS = 0.4744847401650283, VAL-ACC = 0.7589118198874296\n",
      "Epoch 8 starts.\n",
      "Iter 0, loss = 0.47264742851257324, val_acc = 0.7589118198874296\n",
      "Iter 50, loss = 0.45718953013420105, val_acc = 0.774859287054409\n",
      "Iter 100, loss = 0.43584802746772766, val_acc = 0.7804878048780488\n",
      "Iter 133, loss = 0.4283936619758606, val_acc = 0.7786116322701688\n",
      "Epoch 8: LOSS = 0.45949726796498264, VAL-ACC = 0.7786116322701688\n",
      "Epoch 9 starts.\n",
      "Iter 0, loss = 0.3923001289367676, val_acc = 0.7786116322701688\n",
      "Iter 50, loss = 0.4316580295562744, val_acc = 0.7598499061913696\n",
      "Iter 100, loss = 0.4553338587284088, val_acc = 0.773921200750469\n",
      "Iter 133, loss = 0.4106121063232422, val_acc = 0.7607879924953096\n",
      "Epoch 9: LOSS = 0.4458342000950862, VAL-ACC = 0.7607879924953096\n",
      "Epoch 10 starts.\n",
      "Iter 0, loss = 0.420421838760376, val_acc = 0.7607879924953096\n",
      "Iter 50, loss = 0.42636293172836304, val_acc = 0.773921200750469\n",
      "Iter 100, loss = 0.388954758644104, val_acc = 0.7701688555347092\n",
      "Iter 133, loss = 0.37277472019195557, val_acc = 0.7682926829268293\n",
      "Epoch 10: LOSS = 0.43576150110168177, VAL-ACC = 0.7682926829268293\n",
      "Epoch 11 starts.\n",
      "Iter 0, loss = 0.4328412413597107, val_acc = 0.7682926829268293\n",
      "Iter 50, loss = 0.47359898686408997, val_acc = 0.7729831144465291\n",
      "Iter 100, loss = 0.4058248996734619, val_acc = 0.7682926829268293\n",
      "Iter 133, loss = 0.41617658734321594, val_acc = 0.7692307692307693\n",
      "Epoch 11: LOSS = 0.4300991977653364, VAL-ACC = 0.7692307692307693\n",
      "Epoch 12 starts.\n",
      "Iter 0, loss = 0.43759816884994507, val_acc = 0.7692307692307693\n",
      "Iter 50, loss = 0.4282129108905792, val_acc = 0.7729831144465291\n",
      "Iter 100, loss = 0.4064245820045471, val_acc = 0.7720450281425891\n",
      "Iter 133, loss = 0.3744983673095703, val_acc = 0.7673545966228893\n",
      "Epoch 12: LOSS = 0.4202381692228526, VAL-ACC = 0.7673545966228893\n",
      "Epoch 13 starts.\n",
      "Iter 0, loss = 0.45839208364486694, val_acc = 0.7673545966228893\n",
      "Iter 50, loss = 0.4558084011077881, val_acc = 0.774859287054409\n",
      "Iter 100, loss = 0.38271990418434143, val_acc = 0.7814258911819888\n",
      "Iter 133, loss = 0.3722721338272095, val_acc = 0.7889305816135085\n",
      "Epoch 13: LOSS = 0.41808166164551336, VAL-ACC = 0.7889305816135085\n",
      "Epoch 14 starts.\n",
      "Iter 0, loss = 0.43269261717796326, val_acc = 0.7889305816135085\n",
      "Iter 50, loss = 0.40704143047332764, val_acc = 0.7729831144465291\n",
      "Iter 100, loss = 0.4184255003929138, val_acc = 0.7523452157598499\n",
      "Iter 133, loss = 0.3721928298473358, val_acc = 0.7626641651031895\n",
      "Epoch 14: LOSS = 0.4380396310865444, VAL-ACC = 0.7626641651031895\n",
      "Epoch 15 starts.\n",
      "Iter 0, loss = 0.4695630669593811, val_acc = 0.7626641651031895\n",
      "Iter 50, loss = 0.46287137269973755, val_acc = 0.7673545966228893\n",
      "Iter 100, loss = 0.43951767683029175, val_acc = 0.7720450281425891\n",
      "Iter 133, loss = 0.42989814281463623, val_acc = 0.7814258911819888\n",
      "Epoch 15: LOSS = 0.4502558277471222, VAL-ACC = 0.7814258911819888\n",
      "Epoch 16 starts.\n",
      "Iter 0, loss = 0.4191508889198303, val_acc = 0.7814258911819888\n",
      "Iter 50, loss = 0.37908223271369934, val_acc = 0.7823639774859287\n",
      "Iter 100, loss = 0.39496827125549316, val_acc = 0.7795497185741088\n",
      "Iter 133, loss = 0.4184871017932892, val_acc = 0.774859287054409\n",
      "Epoch 16: LOSS = 0.4261281335875936, VAL-ACC = 0.774859287054409\n",
      "Epoch 17 starts.\n",
      "Iter 0, loss = 0.40841954946517944, val_acc = 0.774859287054409\n",
      "Iter 50, loss = 0.41902396082878113, val_acc = 0.7701688555347092\n",
      "Iter 100, loss = 0.3918020725250244, val_acc = 0.774859287054409\n",
      "Iter 133, loss = 0.37220755219459534, val_acc = 0.7814258911819888\n",
      "Epoch 17: LOSS = 0.41292663669064095, VAL-ACC = 0.7814258911819888\n",
      "Epoch 18 starts.\n",
      "Iter 0, loss = 0.3976980149745941, val_acc = 0.7814258911819888\n",
      "Iter 50, loss = 0.41222262382507324, val_acc = 0.7682926829268293\n",
      "Iter 100, loss = 0.42265450954437256, val_acc = 0.7636022514071295\n",
      "Iter 133, loss = 0.3720991611480713, val_acc = 0.7701688555347092\n",
      "Epoch 18: LOSS = 0.4176116322513914, VAL-ACC = 0.7701688555347092\n",
      "Epoch 19 starts.\n",
      "Iter 0, loss = 0.36722996830940247, val_acc = 0.7701688555347092\n",
      "Iter 50, loss = 0.39611750841140747, val_acc = 0.7720450281425891\n",
      "Iter 100, loss = 0.39073890447616577, val_acc = 0.7682926829268293\n",
      "Iter 133, loss = 0.37222135066986084, val_acc = 0.7823639774859287\n",
      "Epoch 19: LOSS = 0.40968797546233576, VAL-ACC = 0.7823639774859287\n",
      "Epoch 20 starts.\n",
      "Iter 0, loss = 0.36131903529167175, val_acc = 0.7823639774859287\n",
      "Iter 50, loss = 0.38097843527793884, val_acc = 0.7776735459662288\n",
      "Iter 100, loss = 0.39733195304870605, val_acc = 0.773921200750469\n",
      "Iter 133, loss = 0.37213972210884094, val_acc = 0.774859287054409\n",
      "Epoch 20: LOSS = 0.4004497360574068, VAL-ACC = 0.774859287054409\n",
      "Epoch 21 starts.\n",
      "Iter 0, loss = 0.3605649173259735, val_acc = 0.774859287054409\n",
      "Iter 50, loss = 0.40474164485931396, val_acc = 0.775797373358349\n",
      "Iter 100, loss = 0.4149957299232483, val_acc = 0.7692307692307693\n",
      "Iter 133, loss = 0.3721126616001129, val_acc = 0.775797373358349\n",
      "Epoch 21: LOSS = 0.404119101536535, VAL-ACC = 0.775797373358349\n",
      "Epoch 22 starts.\n",
      "Iter 0, loss = 0.37532466650009155, val_acc = 0.775797373358349\n",
      "Iter 50, loss = 0.36880141496658325, val_acc = 0.7870544090056285\n",
      "Iter 100, loss = 0.3850365877151489, val_acc = 0.776735459662289\n",
      "Iter 133, loss = 0.37212568521499634, val_acc = 0.7842401500938087\n",
      "Epoch 22: LOSS = 0.3957330534492966, VAL-ACC = 0.7842401500938087\n",
      "Epoch 23 starts.\n",
      "Iter 0, loss = 0.37148743867874146, val_acc = 0.7842401500938087\n",
      "Iter 50, loss = 0.37195077538490295, val_acc = 0.773921200750469\n",
      "Iter 100, loss = 0.37623289227485657, val_acc = 0.7711069418386491\n",
      "Iter 133, loss = 0.36488303542137146, val_acc = 0.7711069418386491\n",
      "Epoch 23: LOSS = 0.3952893562560534, VAL-ACC = 0.7711069418386491\n",
      "Epoch 24 starts.\n",
      "Iter 0, loss = 0.3442319333553314, val_acc = 0.7711069418386491\n",
      "Iter 50, loss = 0.36015963554382324, val_acc = 0.7729831144465291\n",
      "Iter 100, loss = 0.3632381558418274, val_acc = 0.7711069418386491\n",
      "Iter 133, loss = 0.3132711946964264, val_acc = 0.7729831144465291\n",
      "Epoch 24: LOSS = 0.3921583882213509, VAL-ACC = 0.7729831144465291\n",
      "Epoch 25 starts.\n",
      "Iter 0, loss = 0.37533992528915405, val_acc = 0.7729831144465291\n",
      "Iter 50, loss = 0.36791014671325684, val_acc = 0.773921200750469\n",
      "Iter 100, loss = 0.3760471045970917, val_acc = 0.776735459662289\n",
      "Iter 133, loss = 0.3132637143135071, val_acc = 0.7711069418386491\n",
      "Epoch 25: LOSS = 0.3865627470242716, VAL-ACC = 0.7711069418386491\n",
      "Epoch 26 starts.\n",
      "Iter 0, loss = 0.34529805183410645, val_acc = 0.7711069418386491\n",
      "Iter 50, loss = 0.3913640081882477, val_acc = 0.7673545966228893\n",
      "Iter 100, loss = 0.3730275332927704, val_acc = 0.7814258911819888\n",
      "Iter 133, loss = 0.31348538398742676, val_acc = 0.776735459662289\n",
      "Epoch 26: LOSS = 0.41447141331477755, VAL-ACC = 0.776735459662289\n",
      "Epoch 27 starts.\n",
      "Iter 0, loss = 0.3477519750595093, val_acc = 0.776735459662289\n",
      "Iter 50, loss = 0.3603174090385437, val_acc = 0.774859287054409\n",
      "Iter 100, loss = 0.4049178659915924, val_acc = 0.7786116322701688\n",
      "Iter 133, loss = 0.3141017258167267, val_acc = 0.7729831144465291\n",
      "Epoch 27: LOSS = 0.392906085853159, VAL-ACC = 0.7729831144465291\n",
      "Epoch 28 starts.\n",
      "Iter 0, loss = 0.34030407667160034, val_acc = 0.7729831144465291\n",
      "Iter 50, loss = 0.360746830701828, val_acc = 0.775797373358349\n",
      "Iter 100, loss = 0.3840414881706238, val_acc = 0.7729831144465291\n",
      "Iter 133, loss = 0.3204578459262848, val_acc = 0.7636022514071295\n",
      "Epoch 28: LOSS = 0.3834787940021849, VAL-ACC = 0.7636022514071295\n",
      "Epoch 29 starts.\n",
      "Iter 0, loss = 0.3291352391242981, val_acc = 0.7636022514071295\n",
      "Iter 50, loss = 0.36485981941223145, val_acc = 0.7645403377110694\n",
      "Iter 100, loss = 0.37598544359207153, val_acc = 0.775797373358349\n",
      "Iter 133, loss = 0.3132862150669098, val_acc = 0.7711069418386491\n",
      "Epoch 29: LOSS = 0.37933149651019243, VAL-ACC = 0.7711069418386491\n",
      "Epoch 30 starts.\n",
      "Iter 0, loss = 0.3461296558380127, val_acc = 0.7711069418386491\n",
      "Iter 50, loss = 0.36259856820106506, val_acc = 0.7645403377110694\n",
      "Iter 100, loss = 0.38216036558151245, val_acc = 0.7673545966228893\n",
      "Iter 133, loss = 0.313268780708313, val_acc = 0.7701688555347092\n",
      "Epoch 30: LOSS = 0.37592968366441937, VAL-ACC = 0.7701688555347092\n",
      "Epoch 31 starts.\n",
      "Iter 0, loss = 0.3291686177253723, val_acc = 0.7701688555347092\n",
      "Iter 50, loss = 0.38149505853652954, val_acc = 0.7645403377110694\n",
      "Iter 100, loss = 0.3777150511741638, val_acc = 0.7673545966228893\n",
      "Iter 133, loss = 0.3132627308368683, val_acc = 0.7654784240150094\n",
      "Epoch 31: LOSS = 0.37740280919701513, VAL-ACC = 0.7654784240150094\n",
      "Epoch 32 starts.\n",
      "Iter 0, loss = 0.3551200032234192, val_acc = 0.7654784240150094\n",
      "Iter 50, loss = 0.37419506907463074, val_acc = 0.7711069418386491\n",
      "Iter 100, loss = 0.37708762288093567, val_acc = 0.7692307692307693\n",
      "Iter 133, loss = 0.31326770782470703, val_acc = 0.7701688555347092\n",
      "Epoch 32: LOSS = 0.37272244104503716, VAL-ACC = 0.7701688555347092\n",
      "Epoch 33 starts.\n",
      "Iter 0, loss = 0.3294742703437805, val_acc = 0.7701688555347092\n",
      "Iter 50, loss = 0.3728095293045044, val_acc = 0.7673545966228893\n",
      "Iter 100, loss = 0.37595614790916443, val_acc = 0.7776735459662288\n",
      "Iter 133, loss = 0.3135368227958679, val_acc = 0.7776735459662288\n",
      "Epoch 33: LOSS = 0.3763652946392115, VAL-ACC = 0.7776735459662288\n",
      "Epoch 34 starts.\n",
      "Iter 0, loss = 0.3407398760318756, val_acc = 0.7776735459662288\n",
      "Iter 50, loss = 0.39582520723342896, val_acc = 0.7823639774859287\n",
      "Iter 100, loss = 0.3758314549922943, val_acc = 0.7795497185741088\n",
      "Iter 133, loss = 0.31333255767822266, val_acc = 0.7729831144465291\n",
      "Epoch 34: LOSS = 0.3797783122880615, VAL-ACC = 0.7729831144465291\n",
      "Epoch 35 starts.\n",
      "Iter 0, loss = 0.3370340168476105, val_acc = 0.7729831144465291\n",
      "Iter 50, loss = 0.37595000863075256, val_acc = 0.774859287054409\n",
      "Iter 100, loss = 0.375906765460968, val_acc = 0.774859287054409\n",
      "Iter 133, loss = 0.3449135422706604, val_acc = 0.7645403377110694\n",
      "Epoch 35: LOSS = 0.3752810711408184, VAL-ACC = 0.7645403377110694\n",
      "Epoch 36 starts.\n",
      "Iter 0, loss = 0.3507138788700104, val_acc = 0.7645403377110694\n",
      "Iter 50, loss = 0.4034387767314911, val_acc = 0.7654784240150094\n",
      "Iter 100, loss = 0.3761315643787384, val_acc = 0.7692307692307693\n",
      "Iter 133, loss = 0.3133157789707184, val_acc = 0.7626641651031895\n",
      "Epoch 36: LOSS = 0.38756401282157343, VAL-ACC = 0.7626641651031895\n",
      "Epoch 37 starts.\n",
      "Iter 0, loss = 0.36015790700912476, val_acc = 0.7626641651031895\n",
      "Iter 50, loss = 0.36963963508605957, val_acc = 0.7786116322701688\n",
      "Iter 100, loss = 0.37675872445106506, val_acc = 0.7729831144465291\n",
      "Iter 133, loss = 0.31326478719711304, val_acc = 0.7786116322701688\n",
      "Epoch 37: LOSS = 0.3790395231577602, VAL-ACC = 0.7786116322701688\n",
      "Epoch 38 starts.\n",
      "Iter 0, loss = 0.35411787033081055, val_acc = 0.7786116322701688\n",
      "Iter 50, loss = 0.37555384635925293, val_acc = 0.774859287054409\n",
      "Iter 100, loss = 0.3758673071861267, val_acc = 0.7682926829268293\n",
      "Iter 133, loss = 0.3132660388946533, val_acc = 0.776735459662289\n",
      "Epoch 38: LOSS = 0.3706435722156163, VAL-ACC = 0.776735459662289\n",
      "Epoch 39 starts.\n",
      "Iter 0, loss = 0.3334774672985077, val_acc = 0.776735459662289\n",
      "Iter 50, loss = 0.4076772630214691, val_acc = 0.7682926829268293\n",
      "Iter 100, loss = 0.3932686448097229, val_acc = 0.7692307692307693\n",
      "Iter 133, loss = 0.3133992850780487, val_acc = 0.7701688555347092\n",
      "Epoch 39: LOSS = 0.37715407749162105, VAL-ACC = 0.7701688555347092\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkAAAAGwCAYAAABB4NqyAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuNSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/xnp5ZAAAACXBIWXMAAA9hAAAPYQGoP6dpAABZ7klEQVR4nO3deVxU9d4H8M8szAzrALIvgrigiKKiIm5pUtjikreblWla6c3suZnXunm7V8tuWVZetSzNcmtRW9wqc8MlFxQFcUUUZFM2AWHYl5nz/IGMoqgsM3MY5vN+veb1yMyZc77Hc3v4+FslgiAIICIiIrIgUrELICIiIjI1BiAiIiKyOAxAREREZHEYgIiIiMjiMAARERGRxWEAIiIiIovDAEREREQWRy52Aa2RTqdDZmYm7O3tIZFIxC6HiIiIGkEQBBQXF8PLywtS6b3beBiAGpCZmQlfX1+xyyAiIqJmyMjIgI+Pzz2PYQBqgL29PYDav0AHBweRqyEiIqLG0Gg08PX11f8evxcGoAbUdXs5ODgwABEREZmZxgxf4SBoIiIisjgMQERERGRxGICIiIjI4nAMEBERWRytVovq6mqxy6AmsrKygkwmM8i5GICIiMhiCIKA7OxsFBYWil0KNZOjoyM8PDxavE4fAxAREVmMuvDj5uYGGxsbLnZrRgRBQFlZGXJzcwEAnp6eLTofAxAREVkErVarDz/t2rUTuxxqBmtrawBAbm4u3NzcWtQdxkHQRERkEerG/NjY2IhcCbVE3fNr6RguBiAiIrIo7PYyb4Z6fgxAREREZHEYgIiIiMjiMAARERFZEH9/fyxevLhF51izZg0cHR0NUo9YOAvMhGq0OmRrKiCXSuGhVoldDhERmYlhw4ahV69eLQ4uAHD8+HHY2tq2vCgzxxYgE/p090UM/mgflh9IFrsUIiJqQwRBQE1NTaOOdXV15Uw4MACZlLdj7foFV66Xi1wJEREBNxbXq6ox+UsQhEbXOHnyZBw4cABLliyBRCKBRCLBmjVrIJFI8McffyA0NBRKpRKHDh1CcnIyxowZA3d3d9jZ2aFfv37Ys2dPvfPd3gUmkUjw9ddf44knnoCNjQ06d+6Mbdu2Nfnv8ssvv0THjh2hUCgQGBiIb7/9tt7f8zvvvIP27dtDqVTCy8sLf//73/Wff/HFF+jcuTNUKhXc3d3x5JNPNvn6TcUuMBPydqoLQGUiV0JERABQXq1F0NydJr/u+fmRsFE07lfwkiVLcPHiRQQHB2P+/PkAgHPnzgEA3nrrLXzyyScICAiAk5MTMjIy8Oijj+L999+HUqnEunXrMGrUKCQmJqJ9+/Z3vca7776LhQsX4uOPP8Znn32GCRMmIC0tDc7Ozo2qcfPmzXjttdewePFiRERE4LfffsOUKVPg4+OD4cOH45dffsH//vc/bNiwAd27d0d2djZOnToFADhx4gT+/ve/49tvv8XAgQNRUFCAgwcPNuq6LcEAZEI+N1qArhayBYiIiBpHrVZDoVDAxsYGHh4eAIALFy4AAObPn4+HHnpIf6yzszNCQkL0P7/33nvYvHkztm3bhldfffWu15g8eTKeeeYZAMAHH3yApUuXIiYmBiNHjmxUjZ988gkmT56MV155BQAwa9YsHD16FJ988gmGDx+O9PR0eHh4ICIiAlZWVmjfvj369+8PAEhPT4etrS0ef/xx2Nvbw8/PD717927C31DzMACZUF0LUHFFDTQV1XBQWYlcERGRZbO2kuH8/EhRrmsIffv2rfdzSUkJ3nnnHfz+++/IyspCTU0NysvLkZ6efs/z9OzZU/9nW1tbODg46Pfc6t69O9LS0gAAQ4YMwR9//HHH9xMSEjBt2rR67w0aNAhLliwBAPz1r3/F4sWLERAQgJEjR+LRRx/FqFGjIJfL8dBDD8HPz0//2ciRI/XdccYk+higZcuWwd/fHyqVCmFhYYiJibnn8YWFhZgxYwY8PT2hVCrRpUsXbN++vUXnNBUbhRzOtgoAwFWOAyIiEp1EIoGNQm7yl6FWM759Ntfs2bOxefNmfPDBBzh48CDi4+PRo0cPVFVV3fM8Vlb1/0EukUig0+kAANu3b0d8fDzi4+Px9ddfN6tOX19fJCYm4osvvoC1tTVeeeUVDB06FNXV1bC3t0dcXBzWr18PT09PzJ07FyEhISgsLGzWtRpL1AC0ceNGzJo1C/PmzUNcXBxCQkIQGRmpT523q6qqwkMPPYTU1FT8/PPPSExMxMqVK+Ht7d3sc5oaB0ITEVFTKRQKaLXa+x53+PBhTJ48GU888QR69OgBDw8PpKamtujafn5+6NSpEzp16lTv9+2tunXrhsOHD99RS1BQkP5na2trjBo1CkuXLsX+/fsRHR2NM2fOAADkcjkiIiKwcOFCnD59Gqmpqdi7d2+L6r4fUbvAFi1ahKlTp2LKlCkAgOXLl+P333/HqlWr8NZbb91x/KpVq1BQUIAjR47o06q/v3+Lzmlq3o7WOHO1CFc5EJqIiBrJ398fx44dQ2pqKuzs7PStM7fr3LkzNm3ahFGjRkEikeA///nPXY81pDfeeANPPfUUevfujYiICPz666/YtGmTfgbamjVroNVqERYWBhsbG3z33XewtraGn58ffvvtN1y+fBlDhw6Fk5MTtm/fDp1Oh8DAQKPWLFoLUFVVFWJjYxEREXGzGKkUERERiI6ObvA727ZtQ3h4OGbMmAF3d3cEBwfjgw8+0Kfi5pwTACorK6HRaOq9jMXHiQOhiYioaWbPng2ZTIagoCC4urredUzPokWL4OTkhIEDB2LUqFGIjIxEnz59jF7f2LFjsWTJEnzyySfo3r07VqxYgdWrV2PYsGEAAEdHR6xcuRKDBg1Cz549sWfPHvz6669o164dHB0dsWnTJjz44IPo1q0bli9fjvXr16N79+5GrVm0FqC8vDxotVq4u7vXe9/d3V0/uv12ly9fxt69ezFhwgRs374dSUlJeOWVV1BdXY158+Y165wAsGDBArz77rstv6lGuDkVngGIiIgap0uXLnf8Q37y5Ml3HOfv739H19GMGTPq/Xx7l1hDaxLdb/zN5MmT77j+9OnTMX369AaPHzt2LMaOHdvgZ4MHD8b+/fvveT1jEH0QdFPodDq4ubnhq6++QmhoKMaPH4+3334by5cvb9F558yZg6KiIv0rIyPDQBXfyZtT4YmIiEQnWguQi4sLZDIZcnJy6r2fk5OjX+fgdp6enrCysoJMdnP6YLdu3ZCdnY2qqqpmnRMAlEollEplC+6m8epagDgLjIiISDyitQApFAqEhoYiKipK/55Op0NUVBTCw8Mb/M6gQYOQlJRUb0DXxYsX4enpCYVC0axzmpqPU+26BvmlVSiraty+LURERGRYonaBzZo1CytXrsTatWuRkJCA6dOno7S0VD+Da9KkSZgzZ47++OnTp6OgoACvvfYaLl68iN9//x0ffPBBvf7N+51TbGprK9graxveMtkNRkRkck3Zh4taH0M9P1GnwY8fPx7Xrl3D3LlzkZ2djV69emHHjh36Qczp6emQSm9mNF9fX+zcuROvv/46evbsCW9vb7z22mv45z//2ehztgbeTta4kF2MK9fL0cnNXuxyiIgsQt3yKWVlZbC2tha5GmqusrLaZWRuX7yxqSQCo/AdNBoN1Go1ioqK4ODgYPDzv7T2OPYk5OL9J4IxIczP4OcnIqKGZWVlobCwEG5ubrCxsTHYisxkfIIgoKysDLm5uXB0dISnp+cdxzTl9zf3AhMBV4MmIhJH3YSY1rI7ADWdo6PjPSc2NRYDkAg4E4yISBwSiQSenp5wc3NDdXW12OVQE90+E7wlGIBEUDcTjGsBERGJQyaTGewXKZkns1oIsa242QXG/cCIiIjEwAAkgrousNziSlTVGH+TOiIiIqqPAUgE7WwVUFlJIQhAVhG7wYiIiEyNAUgEEomEM8GIiIhExAAkEu+6gdAMQERERCbHACQSfQsQZ4IRERGZHAOQSHy4FhAREZFoGIBEUheAOBWeiIjI9BiARFLXBcbFEImIiEyPAUgkdWsBZRdVoEbLtYCIiIhMiQFIJG72KljJJKjRCcgprhS7HCIiIovCACQSmVQCTzUHQhMREYmBAUhEN8cBcSA0ERGRKTEAiYhT4YmIiMTBACQibyduh0FERCQGBiARcSo8ERGROBiAROTNLjAiIiJRMACJyPfGhqhXCsuh0wkiV0NERGQ5GIBE5KFWQSoBqmp0yCvlWkBERESmwgAkIiuZFO4OKgDsBiMiIjIlBiCR+XAmGBERkckxAImMM8GIiIhMjwFIZJwJRkREZHoMQCLzdqydCcYWICIiItNhABLZzTFA3A+MiIjIVBiARHZrF5ggcC0gIiIiU2AAElndIOjSKi2KyqtFroaIiMgyMACJTGUlg4udEgCnwhMREZkKA1ArwF3hiYiITIsBqBXw4VpAREREJsUA1ApwJhgREZFpMQC1AlwMkYiIyLQYgFoBbodBRERkWgxArYC+BYgBiIiIyCQYgFqBuhagwrJqlFTWiFwNERFR28cA1ArYq6ygtrYCwHFAREREpsAA1ErcHAfEmWBERETGxgDUSvhwMUQiIiKTYQBqJTgVnoiIyHQYgFqJui6wK5wJRkREZHQMQK0Eu8CIiIhMhwGolfBxsgHALjAiIiJTYABqJeq6wPJKKlFRrRW5GiIioraNAaiVcLSxgo1CBgDI5DggIiIio2IAaiUkEgnHAREREZkIA1Arwk1RiYiITIMBqBXhWkBERESmwQDUing71s4Eu3Kd22EQEREZEwNQK1I3BohdYERERMbFANSKsAuMiIjINBiAWhGfG4OgszUVqNbqRK6GiIio7WIAakVc7JRQyKXQCUB2UYXY5RAREbVZDECtiFQqubkpKrvBiIiIjIYBqJXhWkBERETGxwDUytxsAeJUeCIiImNhAGplfDgTjIiIyOgYgFoZb64FREREZHQMQK0MB0ETEREZX6sIQMuWLYO/vz9UKhXCwsIQExNz12PXrFkDiURS76VSqeodM3ny5DuOGTlypLFvwyB8nGu3w8gqKodOJ4hcDRERUdskF7uAjRs3YtasWVi+fDnCwsKwePFiREZGIjExEW5ubg1+x8HBAYmJifqfJRLJHceMHDkSq1ev1v+sVCoNX7wRuNsrIZNKUK0VkFtcCQ+16v5fIiIioiYRvQVo0aJFmDp1KqZMmYKgoCAsX74cNjY2WLVq1V2/I5FI4OHhoX+5u7vfcYxSqax3jJOT013PV1lZCY1GU+8lFrlMCg+H2tBztZAzwYiIiIxB1ABUVVWF2NhYRERE6N+TSqWIiIhAdHT0Xb9XUlICPz8/+Pr6YsyYMTh37twdx+zfvx9ubm4IDAzE9OnTkZ+ff9fzLViwAGq1Wv/y9fVt2Y21UN1MMI4DIiIiMg5RA1BeXh60Wu0dLTju7u7Izs5u8DuBgYFYtWoVtm7diu+++w46nQ4DBw7ElStX9MeMHDkS69atQ1RUFD766CMcOHAAjzzyCLRabYPnnDNnDoqKivSvjIwMw91kM3gzABERERmV6GOAmio8PBzh4eH6nwcOHIhu3bphxYoVeO+99wAATz/9tP7zHj16oGfPnujYsSP279+PESNG3HFOpVLZqsYI+XA1aCIiIqMStQXIxcUFMpkMOTk59d7PycmBh4dHo85hZWWF3r17Iykp6a7HBAQEwMXF5Z7HtCZsASIiIjIuUQOQQqFAaGgooqKi9O/pdDpERUXVa+W5F61WizNnzsDT0/Oux1y5cgX5+fn3PKY18XGqnQp/ldthEBERGYXos8BmzZqFlStXYu3atUhISMD06dNRWlqKKVOmAAAmTZqEOXPm6I+fP38+du3ahcuXLyMuLg7PPfcc0tLS8NJLLwGoHSD9xhtv4OjRo0hNTUVUVBTGjBmDTp06ITIyUpR7bKpbN0QVBK4FREREZGiijwEaP348rl27hrlz5yI7Oxu9evXCjh079AOj09PTIZXezGnXr1/H1KlTkZ2dDScnJ4SGhuLIkSMICgoCAMhkMpw+fRpr165FYWEhvLy88PDDD+O9995rVeN87sXTsXYafEW1DvmlVXCxM4+6iYiIzIVEYBPDHTQaDdRqNYqKiuDg4CBKDWEf7EGOphJbZwxCiK+jKDUQERGZk6b8/ha9C4wa5s2ZYEREREbDANRKeesHQjMAERERGRoDUCt1c1d4zgQjIiIyNAagVqpuOwx2gRERERkeA1ArxcUQiYiIjIcBqJXSb4fBAERERGRwDECtVF0LUHFlDYrKq0WuhoiIqG1hAGqlbBRyuNgpAAApeaUiV0NERNS2MAC1Yj281QCAuLTrIldCRETUtjAAtWJ9/Z0BALEMQERERAbFANSKhfo5AQBOpBVwU1QiIiIDYgBqxUJ8HCGXSpCjqeR0eCIiIgNiAGrFrBUydL8xDojdYERERIbDANTK9b2lG4yIiIgMgwGoldOPA0plCxAREZGhMAC1cnUtQIk5xdBUcEFEIiIiQ2AAauXcHFTwdbaGIAAn0wvFLoeIiKhNYAAyA339bqwHlMpxQERERIbAAGQGbq4HxHFAREREhsAAZAb6+tcGoPiMQtRodSJXQ0REZP4YgMxAFzd72KvkKKvS4kJ2sdjlEBERmT0GIDMglUrQp33ddHiOAyIiImopBiAz0ZfjgIiIiAyGAchMhN4YB8QtMYiIiFqOAchM9PJ1hEwqQVZRBa4WcmNUIiKilmAAMhM2Cjm6ezkA4DggIiKilmIAMiN16wGxG4yIiKhlGIDMSN2K0NwYlYiIqGUYgMxI3YKIF7I1KKmsEbkaIiIi88UAZEbcHVTwcbKGTgBOprMViIiIqLkYgMyMfj0gdoMRERE1GwOQmQn1v7EzPAdCExERNRsDkJmpawE6mX6dG6MSERE1EwOQmenibg97pRyl3BiViIio2RiAzIxMKkFvrgdERETUIgxAZogboxIREbUMA5AZqgtAsdwSg4iIqFkYgMxQr/a1G6NmFlUgkxujEhERNRkDkBmyUcgR5Fm7MSrHARERETUdA5CZ4saoREREzccAZKbq9gU7kcZxQERERE3FAGSm6naGT8gqRik3RiUiImoSBiAz5aFWwdvRGlqdgPiMQrHLISIiMisMQGYslBujEhERNQsDkBnjOCAiIqLmYQAyY6H6jVELodUJIldDRERkPhiAzFhXDwfYKeUoqaxBIjdGJSIiajQGIDMmk0rQu70jACCW3WBERESNxgBk5kK5MSoREVGTMQCZubr1gDgTjIiIqPEYgMxcr/aOkEqAq4XlyC6qELscIiIis8AAZObslHJ0u7ExKqfDExERNQ4DUBvQlwsiEhERNQkDUBsQ6l87Dog7wxMRETUOA1AbUNcCdD5Lw41RiYiIGoEBqA3wcrSGl1oFrU7AKW6MSkREdF8MQG0Eu8GIiIgajwGojajrBvsxNgM5Gk6HJyIiuhcGoDZidIgXfJyskVFQjme+OopchiAiIqK7YgBqI5xsFVg/dQC8Ha1xOa8UT688itxihiAiIqKGtIoAtGzZMvj7+0OlUiEsLAwxMTF3PXbNmjWQSCT1XiqVqt4xgiBg7ty58PT0hLW1NSIiInDp0iVj34bofJ1tsGHaAHipVbh8rRTPrjyGa8WVYpdFRETU6ogegDZu3IhZs2Zh3rx5iIuLQ0hICCIjI5Gbm3vX7zg4OCArK0v/SktLq/f5woULsXTpUixfvhzHjh2Dra0tIiMjUVHR9ltEakNQODzVKiTlluDZlUeRV8IQREREdCvRA9CiRYswdepUTJkyBUFBQVi+fDlsbGywatWqu35HIpHAw8ND/3J3d9d/JggCFi9ejH//+98YM2YMevbsiXXr1iEzMxNbtmwxwR2Jr307G6yfOgAeDipcyi3BhJXHkM8QREREpCdqAKqqqkJsbCwiIiL070mlUkRERCA6Ovqu3yspKYGfnx98fX0xZswYnDt3Tv9ZSkoKsrOz651TrVYjLCzsruesrKyERqOp9zJ3/i62WD9tANzslUjMKcaEr4+hoLRK7LKIiIhaBVEDUF5eHrRabb0WHABwd3dHdnZ2g98JDAzEqlWrsHXrVnz33XfQ6XQYOHAgrly5AgD67zXlnAsWLIBarda/fH19W3prrUKHGyHI1V6JC9m1Ieg6QxAREZH4XWBNFR4ejkmTJqFXr1544IEHsGnTJri6umLFihXNPuecOXNQVFSkf2VkZBiwYnF1dLXD+qkD4GKnREKWBs99cwyFZQxBRERk2UQNQC4uLpDJZMjJyan3fk5ODjw8PBp1DisrK/Tu3RtJSUkAoP9eU86pVCrh4OBQ79WWdHKzw/qpYXCxU+BcpgYTv4lBUVm12GURERGJRtQApFAoEBoaiqioKP17Op0OUVFRCA8Pb9Q5tFotzpw5A09PTwBAhw4d4OHhUe+cGo0Gx44da/Q526LO7vb4YeoAtLNV4MzVIkxcdQxF5QxBRERkmUTvAps1axZWrlyJtWvXIiEhAdOnT0dpaSmmTJkCAJg0aRLmzJmjP37+/PnYtWsXLl++jLi4ODz33HNIS0vDSy+9BKB2htjMmTPx3//+F9u2bcOZM2cwadIkeHl5YezYsWLcYqvRxd0e308Ng7OtAqevFGHSqhiUVXH3eCIisjxysQsYP348rl27hrlz5yI7Oxu9evXCjh079IOY09PTIZXezGnXr1/H1KlTkZ2dDScnJ4SGhuLIkSMICgrSH/Pmm2+itLQU06ZNQ2FhIQYPHowdO3bcsWCiJerq4YDvXgzDhK+P4lRGIZZGJeGtR7qKXRYREZFJSQRBEJr6pYyMDEgkEvj4+AAAYmJi8MMPPyAoKAjTpk0zeJGmptFooFarUVRU1ObGA9XZcz4HL607ASuZBDtnDkWAq53YJREREbVIU35/N6sL7Nlnn8W+ffsA1E47f+ihhxATE4O3334b8+fPb84pycRGdHPDsEBXVGsFvPfbebHLISIiMqlmBaCzZ8+if//+AIAff/wRwcHBOHLkCL7//nusWbPGkPWRkUgkEsx9PAhWMgn2JV5DVELO/b9ERETURjQrAFVXV0OpVAIA9uzZg9GjRwMAunbtiqysLMNVR0YV4GqHFwZ3AADM/+08Kqq1IldERERkGs0KQN27d8fy5ctx8OBB7N69GyNHjgQAZGZmol27dgYtkIzr/x7sDDd7JdLyy/DNoRSxyyEiIjKJZgWgjz76CCtWrMCwYcPwzDPPICQkBACwbds2fdcYmQc7pRxzHq2dBfb53iRkFZWLXBEREZHxNWsWGFC7AKFGo4GTk5P+vdTUVNjY2MDNzc1gBYrBEmaB3UoQBPx1eTROpF3HqBAvfPZMb7FLIiIiajKjzwIrLy9HZWWlPvykpaVh8eLFSExMNPvwY4kkEgneGd0dEgnw66lMHL2cL3ZJRERERtWsADRmzBisW7cOAFBYWIiwsDB8+umnGDt2LL788kuDFkimEeytxrP92wMA3tl2DjVancgVERERGU+zAlBcXByGDBkCAPj555/h7u6OtLQ0rFu3DkuXLjVogWQ6sx8OhNraCheyi/FDTLrY5RARERlNswJQWVkZ7O3tAQC7du3CuHHjIJVKMWDAAKSlpRm0QDIdJ1sFZj/cBQDw6a6LKCitErkiIiIi42hWAOrUqRO2bNmCjIwM7Ny5Ew8//DAAIDc31yIGDbdlz4b5oZunA4rKq/HxzkSxyyEiIjKKZgWguXPnYvbs2fD390f//v0RHh4OoLY1qHdvziAyZzKpBO+O7g4A2HA8HWevFolcERERkeE1exp8dnY2srKyEBISot+tPSYmBg4ODuja1bx3F7e0afAN+fv6k9h2KhOhfk74+eVwSCQSsUsiIiK6J6NPgwcADw8P9O7dG5mZmbhy5QoAoH///mYffqjWvx7tBhuFDLFp17H55FWxyyEiIjKoZgUgnU6H+fPnQ61Ww8/PD35+fnB0dMR7770HnY7Tp9sCD7UKrz7YCQCw4I8LKK6oFrkiIiIiw2lWAHr77bfx+eef48MPP8TJkydx8uRJfPDBB/jss8/wn//8x9A1kkheHNwB/u1scK24Ep/vTRK7HCIiIoNp1hggLy8vLF++XL8LfJ2tW7filVdewdWr5t1lwjFAN+29kIMX1pyAlUyCHTOHoqOrndglERERNcjoY4AKCgoaHOvTtWtXFBQUNOeU1Eo92NUdD3Z1Q7VWwL83n4VW16wx80RERK1KswJQSEgIPv/88zve//zzz9GzZ88WF0Wty9zHg2BtJUP05Xws3HlB7HKIiIhaTN6cLy1cuBCPPfYY9uzZo18DKDo6GhkZGdi+fbtBCyTx+bvYYuGTPfF/609ixYHLCPZSY1SIl9hlERERNVuzWoAeeOABXLx4EU888QQKCwtRWFiIcePG4dy5c/j2228NXSO1AqNCvPC3BwIAAG/+fBrnMzUiV0RERNR8zV4IsSGnTp1Cnz59oNVqDXVKUXAQdMO0OgGTV8fg4KU8+DhZ49dXB8PJViF2WURERABMtBAiWR6ZVILPnumN9s42uHK9HP+3/iRqtFz3iYiIzA8DEDWJo40CX00KhY1ChkNJeVjIDVOJiMgMMQBRk3X1cMDHT4YAAL768zK2xpv3uk9ERGR5mjQLbNy4cff8vLCwsCW1kBl5rKcnzmV2xBf7k/HPX06jk5sdunupxS6LiIioUZoUgNTqe/+CU6vVmDRpUosKIvPxj4cDcT5Lg/2J1zBtXSx+/b/BcOagaCIiMgMGnQXWVnAWWOMVlVVj9LJDSMsvw8CO7bDuhf6Qy9izSkREpsdZYGQyahsrrJzUFzYKGY4k52PBH8ZdKTqjoAxvbz6D9Pwyo16HiIjaNgYgarEu7vZY9FTtoOhvDqVg88krRrvWu7+ex/fH0jH7p1Ng4yURETUXAxAZxMhgT7w6vBMA4K1fzuDs1SKDXyMtvxRRF3IAADGpBdh7Idfg1yAiIsvAAEQG8/pDXfBgVzdU1ugwbd0JFJRWGfT8a46kQhAAxY0xRh/tuMDd6YmIqFkYgMhgZFIJ/je+Fzq42CKzqAJLoy4Z7NzFFdX46URt19onT4VAbW2Fizkl2BRnvO42IiJquxiAyKDU1lZ4f2wwAOCHmHTkaioMct6fTlxBSWUNOrraYlRPT8wY3hEAsGj3RVRUm/fec0REZHoMQGRw4R3boa+fE6pqdFjx5+UWn0+rE7A2OhUAMGVQB0gkEkwK94eXWoWsogqsu/EZERFRYzEAkcFJJBL8fURnAMD3x9JwrbiyRefbeyEXafllcFDJMa6PNwBAZSXD6w91AQAs25eMorLqlhVNREQWhQGIjGJIZxf08nVERbUOXx9sWSvQ6sMpAIBnwtrDRnFz8fJxfXzQxd0OReXV+PJAcouuQUREloUBiIxCIpHgtRutQOui05Bf0rxWoIQsDY4k50Mmre32upVMKsE/R3YFUBuSsorKW1QzERFZDgYgMpphga7o4a1GebUW3xxKadY51hxOBQCM7O4Bb0frOz5/sKsb+vs7o7JGh8W7DTfrjIiI2jYGIDKaW8cCrT2SiutNXBcov6QSm+OvAgBeGOx/12v885HaVqCfYjNwKae4+QUTEZHFYAAio4ro5oZung4ordJi1eGmtQKtj0lHVY0OPX3U6NPe6a7Hhfo5IbK7O3QCsHBnYktLJiIiC8AAREZVOxaodouMNYdTGz1bq6pGh3XRaQCAF25Mfb+XNyK7QioBdp/PwYnUgpYVTUREbR4DEBndw0EeCHS3R3FlDVYfaVwr0B9ns5BbXAk3eyUe7eF53+M7udlhfD9fAMCHf1zgRqlERHRPDEBkdFKpBP93oxVo1aEUaCru3QokCAJW3Rg0PXGAHxTyxv3P9LURXaCykuJE2nXsSeBGqUREdHcMQGQSjwZ7orObHTQVNVh3JPWex8alF+LUlSIo5FI8G9a+0dfwUKvwwqAOAICFOy6gRqtrSclERNSGMQCRSUilErz6YG0r0NeHUlBSWXPXY+sGS4/t5YV2dsomXeflYR3haGOFS7kl2BR3tfkFExFRm8YARCbzeE8vBLjYorCs+q77d2UWlmPH2WwAtft+NZWDygqvDq8NWtwolYiI7oYBiExGdmsr0MEUlDbQCrQuOg1anYDwgHbo5unQrOtMDPeDt6M1sjUVWHOf7jYiIrJMDEBkUqNDvODXzgYFpVX4/lhavc/Kq7RYH5MOAJgyyL/Z11DKZfjHw7UbpX6xLwmFZU1bgJGIiNo+BiAyKblMihk3uqi++vMyyqtudlFtOnkFReXVaO9sgxHd3Ft0nTG9vNHVwx6aihp8sZ8bpRIRUX0MQGRyT/T2ho+TNfJKqvDDjRYfQRCw+sa+X88P9IdMeu+FD+9HJr25RcaaI6nIKChr0fmIiKhtYQAik7O6pRVo+YFkVFRrcfBSHpJyS2CnlOOpvj4Guc6wLq4Y1Kkdqmp0eO+38wY5JxERtQ0MQCSKv/TxgZdahWvFldh4PAOrb0x9fzLUB/YqK4NcQyKRYN6o7pBJJdh1PgcHLl4zyHmJiMj8MQCRKBRyKabfaAVaEnUJ+xKvQSIBJg/0N+h1urjb68/57rZzqKrh4ohERMQARCJ6qq8PPBxUKCitnaU1oqsb/F1sDX6d1yI6w8VOict5pfqWJiIismwMQCQapVyG6cM66n9+oRkLHzaGg8oKb90YEL006hJyNBVGuQ4REZkPBiAS1fh+vhjUqR0e7+mJ8I7tjHadcb290bu9I0qrtFiwPcFo1yEiIvPAAESiUlnJ8P1LA/D5s30gkbRs6vu9SKUSzB8dDIkE2BKfiZiUAqNdi4iIWj8GILIYPXzUeLpf7e7yc7ee5W7xREQWjAGILMobkYFQW1vhQnaxfhFGIiKyPAxAZFGcbRWYfWOfsE92JiK/pFLkioiISAytIgAtW7YM/v7+UKlUCAsLQ0xMTKO+t2HDBkgkEowdO7be+5MnT4ZEIqn3GjlypBEqJ3P0bJgfunk6QFNRg092JYpdDhERiUD0ALRx40bMmjUL8+bNQ1xcHEJCQhAZGYnc3Nx7fi81NRWzZ8/GkCFDGvx85MiRyMrK0r/Wr19vjPLJDMmkEswf0x0AsOF4Bk5fKRS3ICIiMjnRA9CiRYswdepUTJkyBUFBQVi+fDlsbGywatWqu35Hq9ViwoQJePfddxEQENDgMUqlEh4eHvqXk5PTXc9XWVkJjUZT70VtWz9/Z4zt5QVBAOZtOwedThC7pFapvEqLcV8cxlMroqHl3xERtSGiBqCqqirExsYiIiJC/55UKkVERASio6Pv+r358+fDzc0NL7744l2P2b9/P9zc3BAYGIjp06cjPz//rscuWLAAarVa//L19W3eDZFZmfNoN9gqZDiZXohf4q6IXU6r9PHORMSlFyImpQDHUu7+3xARkbkRNQDl5eVBq9XC3d293vvu7u7Izs5u8DuHDh3CN998g5UrV971vCNHjsS6desQFRWFjz76CAcOHMAjjzwCrVbb4PFz5sxBUVGR/pWRkdH8myKz4e6gwt9HdAYAfLTjAjQV1SJX1LqcSC3A6iM3tw75/XSWiNUQERmW6F1gTVFcXIyJEydi5cqVcHFxuetxTz/9NEaPHo0ePXpg7Nix+O2333D8+HHs37+/weOVSiUcHBzqvcgyTBnUAQGutsgrqcLi3ZfELqfVqKjW4o2fT0MQgK4e9gCAHWezuXYSEbUZogYgFxcXyGQy5OTk1Hs/JycHHh4edxyfnJyM1NRUjBo1CnK5HHK5HOvWrcO2bdsgl8uRnJzc4HUCAgLg4uKCpKQko9wHmS+FXIp3RtUOiF4bnYqLOcUiV9Q6fLorESl5pXB3UOKHqQPgZGOF/NIqHOMK2kTURogagBQKBUJDQxEVFaV/T6fTISoqCuHh4Xcc37VrV5w5cwbx8fH61+jRozF8+HDEx8ffdezOlStXkJ+fD09PT6PdC5mvoV1cEdndHVqdgHlbz0EQLHuwb1z6dXxzqLbra8G4HnC2VWBkcO0/SH4/w24wImobRO8CmzVrFlauXIm1a9ciISEB06dPR2lpKaZMmQIAmDRpEubMmQMAUKlUCA4OrvdydHSEvb09goODoVAoUFJSgjfeeANHjx5FamoqoqKiMGbMGHTq1AmRkZFi3iq1Yv9+LAhKuRTRl/PxmwWPdamo1uKNn05BJwDj+njjwa614/Me7VH7jwd2gxFRWyF6ABo/fjw++eQTzJ07F7169UJ8fDx27NihHxidnp6OrKzG/0KSyWQ4ffo0Ro8ejS5duuDFF19EaGgoDh48CKVSaazbIDPn62yD6cM6AgD+tfkMUvJKRa5IHIv3XELytVK42isx9/Eg/fvhAe3gZGOFgtIqHL3MbjAiMn8SwdLb+xug0WigVqtRVFTEAdEWpKpGh2dWHkVs2nV0drPD5hmDYKeUi12WyZzKKMQTXxyGTgC+mhiKh7vXH4c3Z9MZrI9JxzP922PBuB4iVUlEdHdN+f0tegsQUWuhkEvx5YQ+cHdQ4lJuCWZtjLeYBRIra7R44+farq8xvbzuCD8A8HjPum6wLHaDEZHZYwAiuoWbgwrLnwuFQibFrvM5+HyfZcwc/CwqCRdzSuBip9DPirtdWAdnONsqcL2sGtGXuSgiEZk3BiCi2/Ru74T/jg0GAPxvz0VEJeTc5xvm7ezVInx5oHYJiffGBMPJVtHgcXKZ9OZsMAseKE5EbQMDEFEDnurni4kD/CAIwMwN8Ui+ViJ2SUZRVaPD7J9OQasT8FhPTzzS495LRTx+4/Od57JRzW4wIjJjDEBEd/Gfx4PQz98JxZU1mLbuBIrb4FYZy/Yl4UJ2MZxtFZg/uuGur1v17+AMF7sb3WDJ7AYjIvPFAER0Fwq5FF9MCIWHgwrJ10rx+sZTbWpQ9PlMDZbdGOM0f0x3tLO7/zIRcpkUkd3ZDUZE5o8BiOgeXO2VWDExFAq5FHsScrB0b9vYL6xaW9v1VaMTMLK7Bx67T9fXrR67MRts53l2gxGR+WIAIrqPEF9HvH9jUPTiPZew61y2yBW13PL9yTifpYGjjRXeGxsMiUTS6O+GdWgHFzsFCsuqcYTdYERkphiAiBrhr319MXmgPwBg1o+nkJRrvoOiE7OL9S1Z747uDlf7pq2QLpNKbpkNlmnw+oiITIEBiKiR3n6sG8I6OKPkxqBojZkOiv50VyKqtQIiurljdIhXs87xWI/a7+08l4OqGnaDEZH5YQAiaiQrmRTLJvSBl1qFy3mleH2D+a0UnVVUjqgLuQCAtx4JbFLX161qZ4MpUVRejcPJeYYskYjIJBiAiJrAxU6JFRP7QimXIupCLhbvuSh2SU2y8XgGtDoB/Ts4o5ObfbPPI5NK8GiP2m6w7ZwNRkRmiAGIqIl6+Kj1m4Eu3ZuEtzefQVlVjchV3V+NVoeNxzMAABPC2rf4fI/esigiu8GIyNwwABE1w7g+Png9ogsA4Ptj6Xh86SGcyigUt6j72Jd4DVlFFXC2VegHMbdEP39nuNoroamoweEkdoMRkXlhACJqptciOuO7F8Pg4VA7Jmjcl0ewNOpSq90p/ftjaQCAv4b6QCmXtfh8MqkEj94IUr+xG4yIzAwDEFELDO7sgh0zh+Cxnp7Q6gQs2n0RT62IRlp+qdil1ZNRUIYDF68BAJ7p3/LurzqP9aydDbbrPLvBiMi8MAARtZCjjQKfP9Mb/xsfAnulHHHphXhkyUFsPJ4OQWgds8Q2HE+HIABDOrvA38XWYOft6+cEN3sliitqcCjpmsHOS0RkbAxARAYgkUjwRG8f/DFzCMI6OKOsSot//nIGf/s2FvkllaLWVq3VYePxKwCAZw3Y+gMAUqlEPxia3WBEZE4YgIgMyMfJBj9MHYA5j3SFlUyCXedzELn4IPbdWHtHDLvP5yCvpBKu9kpEBLkb/Px1e4PtPpeDyhqtwc9PRGQMDEBEBiaTSvC3Bzpiy4xB6OJuh7ySSkxZcxz/3nIG5VWmDwh1g5+f7ucLK5nh/5MPbe8EdwcliitrcOgSZ4MRkXlgACIyku5eamx7dTBeGNQBAPDd0XQ8980xk7aSpOSV4nBSPiQSYHw/X6NcQyqV4JHg2lag39kNRkRmggGIyIhUVjLMHRWE714Mg4NKjti063h781mTDY5eH5MOABge6AYfJxujXefxum6w8+wGIyLzwABEZAKDO7vg82f7QCoBfo69glWHU41+zYpqLX46YbiVn++lT3sneDioUFxZg4MX2Q1GRK0fAxCRiQzt4oq3HwsCALz/+3n8edG408Z3nsvG9bJqeKlVGBboZtRr3Tob7Pcz7AYjotaPAYjIhF4Y5I+/hvpAJwCv/hCHlDzjLZj4/dHa7q+n+7eHTNq8Xd+b4rGetatC7z6fg4pqdoMRUevGAERkQhKJBP99Ihh92jtCU1GDl9Yeh6ai2uDXuZhTjJjUAsikEqMNfr5db18neKpVKKmsMXrrFhFRSzEAEZmYUi7D8omh8FSrkHytFK+tPwmtzrCDon84Vtv6E9HNDe4OKoOe+25u7Qb7+lBKq1kFm4ioIQxARCJws1fhq4l9oZRLsS/xGhbuvGCwc5dXafFLXO3KzxPC/Ax23saYMsgfKispYlIKsPnkVZNem4ioKRiAiETSw0eNj/8aAgBYceAythgoMPx6OhPFFTVo72yDwZ1cDHLOxvJxssHfR3QGALz/ewKKygzfvUdEZAgMQEQiGh3ihRnDOwIA3vzlNE5lFLb4nHXdX8/0bw+pCQY/3+6lwQHo7GaH/NIqg7ZsEREZEgMQkcj+8VAgIrq5oapGh2nfnkCOpqLZ5zp7tQjxGYWwkknw174+Bqyy8RRyKd4bGwwA+CEmHfEGCHVERIbGAEQkMqlUgv+N74XObnbI0VRi2rexzZ5G/sONlZ9HBnvCxU5pyDKbZEBAO4zr7Q1BAN7efMbgg7yJiFqKAYioFbBXWeHr5/tCbW2FUxmF+NemM02eRVVSWYOtN8YRGXvl58b412Pd4KCS41ymBt9Gp4pdDhFRPQxARK2EXztbfDGhD2RSCTadvIqvD6Y06ftb46+itEqLjq62COvgbKQqG8/FTok3R3YFAHy66yJyW9C1R0RkaAxARK3IoE4umPv4je0ytidgzOeHsHDHBRxJzrvnJqOCIOhXfn42zA8SiekHPzfkmf7tEeKjRnFlDf77e4LY5RAR6cnFLoCI6psU7of0gjJ8cygFp64U4dSVInyxPxkqKyn6+TtjcCcXDO7sgm4eDvpZXqeuFOF8lgZKuRR/6eMt8h3cJJNK8P4TPTD680PYdioTT/X1xeDOpp2aT0TUEInA5VrvoNFooFarUVRUBAcHB7HLIQuVXVSBw0l5OHTjda24st7nzrYKDOzYDkM6u+DAxWvYfiYb4/p4Y9FTvcQp+B7e2XYOa46kIsDFFn/MHAKlXCZ2SUTUBjXl9zcDUAMYgKi1EQQBl3JLcOhSbRg6ejkfZVV3don9Mn0gQv2cRKjw3jQV1Rjx6QFcK67ErIe66BdLbAqdTsDJjEIEetjDTsnGayK6EwNQCzEAUWtXVaPDqSuFOHgpD4eT8hCfUYj+/s74YWpYqxn/c7ut8Vfx2oZ4KORS7H59KPza2Tb6uyfTr+OdX8/jVEYhOrraYv3UAXAz0R5nRGQ+GIBaiAGIzE1ljRYKmbTVhh+gthXruW+O4XBSPoYFumL15H73rTdHU4GP/riATbdtE9LBxRY/TA2Dp9ramCUTkZlpyu9vzgIjagOUclmrDj8AIJFI8N6YYChkUuxPvIYdZ7PvemxFtRbL9iVh+Cf79eHnyVAf/DJ9ILwdrZGSV4rxK47iamG5qconojaGAYiITCbA1Q4vPxAAAHj31/Moqayp97kgCNh5LhsP/+9PfLwzEWVVWvTydcSWGYPwyV9DEOrnhI1/G4D2zjZILyjD+BXRyCgoE+NWiMjMMQARkUm9MrwT2jvbIFtTgSV7Lurfv5hTjInfxOBv38YivaAM7g5K/G98CDZNH4hevo7643ycbLDxbwPQwcUWV66XY/yKaKTll4pwJ23ft9GpeG3DSZQ3MOCeyNwxABGRSamsZHh3THcAwKrDqTh6OR/ztp7FI0sO4lBSHhRyKWYM74i9/xiGJ3r7NLijvafaGhumDUBHV1tkFlVg/IqjuHytxNS30qZVVGvxwfYL2BqfiS3xV+//BSIzwwBERCY3PNANjwR7QKsT8PRXR7E2Og1anYDI7u7Y8/oDeCOyK2zvM9Xd3UGFDdPC0dnNDtmaCjz91VEk5TIEGcqxlAKU39iU9+fYKyJXQ2R4DEBEJIq5o4Jgo6hdEDHQ3R7fvxSGFRP7on07m0afw9VeiQ3TBqCrhz1yiyvx9FfRuJhTbKySLcq+C7n6P8emXWcLG7U5DEBEJApPtTV+/Fs4vpjQB7//fTAGdWreFhnt7JT4YeoABHk6IK+kCk9/dRQJWRoDV2t59ifWBiC1tRUA4Jc4tgJR28IARESiCfZW49EenpDLWvb/ipxtFfhhahh6eKtRUFqFZ1YexdmrRQaq0vKk5JUiNb8MVjIJ/vVoVwDAprir0Oq4bBy1HQxARNQmONoo8N1LYejl64jCsmo8u/IoTmUUil2WWarr/urfwRljennDQSVHVlEFjiTniVwZkeEwABFRm6G2tsK3L/ZHqJ8TNBU1eO7rYziXyZagptp3o/treKAbVFYyjO7lBYCDoaltYQAiojbFXmWFdS/0R39/ZxRX1mDK6uNcMboJSitrcOxyAQBgeFc3AMCTob4AgB1ns6GpqBatNiJDYgAiojbHVinHyuf7oou7HXKLKzFldQyKyvmLuzGOJOejSqtDe2cbBLjUblgb4qNGJzc7VNbo8PvpLJErJDIMBiAiapPU1lZYPaU/3OyVuJhTgunfxaKqRid2Wa3eze4vV/3+chKJBE+G+gAAfmE3GLURDEBE1GZ5O1pj1eR+sFXIcCQ5H2/9chqCwJlMdyMIAvbfGAA97Eb3V50nentDKgFOpF1HSh63HiHzxwBERG1asLcayyb0gUwqwaaTV/G/PZfELqnVuphTgsyiCijlUoQHtKv3mbuDCkO7uAJgKxC1DQxARNTmDQt0w/tjgwEAS6Mu4cfjGSJX1DrVdX8N7NgOKivZHZ/ru8HirnBNIDJ7DEBEZBGe7t8e//dgJwDAnM1ncODiNZEran3q1v8Zflv3V52Ibu76NYGik/NNWRqRwTEAEZHFmPVQF4zr7Q2tTsAr38U2eY0gQRBwOCkPz6+KQe/5u7DjbNuZEVVUXo0TadcB1K7/05D6awKxFY3MGwMQEVkMiUSCD//SE+EB7VBapcULa44jsxFrBFVrddhy8ioeW3oIE74+hgMXr+F6WTX+b/1J7L2QY4LKje/QpTxodQI6udnB1/nuG9Lq1wQ6xzWByLwxABGRRVHIpVg+MRRd3O2Qo6nElNXH7/qLvLiiGiv/vIyhC/dh5sZ4nM/SwNpKhskD/fFYD09UawW8/F0cDl0y/y0ibp3+fi91awJVVOuwnWsCkRlrFQFo2bJl8Pf3h0qlQlhYGGJiYhr1vQ0bNkAikWDs2LH13hcEAXPnzoWnpyesra0RERGBS5c484OIat26RlBiTvEdawRlFZVjwfYEDFywF+9vT0BWUQVc7JR4IzIQ0XMexDuju2Px070Q2d0dVTU6vLTuOGJSCkS8o5bR6QTsT6wdE3W37q86t64JxK0xyJyJHoA2btyIWbNmYd68eYiLi0NISAgiIyORm5t7z++lpqZi9uzZGDJkyB2fLVy4EEuXLsXy5ctx7Ngx2NraIjIyEhUVFca6DSIyM7euEXQ4KR9vbTqN85kazNoYjyEf7cOKPy+juLIGndzs8NFfeuDQP4djxvBOcLRRAACsZFIsfaY3hgW6oqJahymrY3Ay/brId9U85zI1yCuphK1Chr7+zvc9nmsCUVsgegBatGgRpk6diilTpiAoKAjLly+HjY0NVq1addfvaLVaTJgwAe+++y4CAgLqfSYIAhYvXox///vfGDNmDHr27Il169YhMzMTW7ZsMfLdEJE5qbdGUNxVPLr0IDadvIoanYABAc5YNbkvds0civH92jc4LVwpl2H5c6EY2LF2TNHzq2Jw9qr5bb5a1/01uLMLFPL7/1rgmkDUFogagKqqqhAbG4uIiAj9e1KpFBEREYiOjr7r9+bPnw83Nze8+OKLd3yWkpKC7OzseudUq9UICwu76zkrKyuh0WjqvYjIMty6RpBUAjze0xPbXh2EDdPC8WBXd0ilknt+X2Ulw9fP90XfGzvQT/zmGC7mFJuidIO5dff3xuKaQGTu5GJePC8vD1qtFu7u7vXed3d3x4ULFxr8zqFDh/DNN98gPj6+wc+zs7P157j9nHWf3W7BggV49913m1g9EbUVT/dvj2BvNZxsFfB2tG7y920Ucqye0g/PfX0Mp64U4dmVx/Dj3wYgwNXOCNUaVn5JJeIzCgHcff2fhty+JtDgzi5GqpDIOETvAmuK4uJiTJw4EStXroSLi+H+Y5szZw6Kior0r4wMrm9BZGmCvdXNCj917FVWWPtCf3TzdEBeSSUmfH0MGQVlBqzQOP68dA2CAAR5OsDdQdXo73FNIDJ3ogYgFxcXyGQy5OTUX0cjJycHHh4edxyfnJyM1NRUjBo1CnK5HHK5HOvWrcO2bdsgl8uRnJys/15jzwkASqUSDg4O9V5ERE3laKPAdy/2Ryc3O2QVVeCZlUeRVXT/dYbEtO/CjdlfXe89/b0hf+lT2w3GNYHIHIkagBQKBUJDQxEVFaV/T6fTISoqCuHh4Xcc37VrV5w5cwbx8fH61+jRozF8+HDEx8fD19cXHTp0gIeHR71zajQaHDt2rMFzEhEZUjs7JX54KQz+7Wxw5Xo5Jqw8htzi1jkDVasT9FuCNGX8T51evo7o6GrLNYHILIneBTZr1iysXLkSa9euRUJCAqZPn47S0lJMmTIFADBp0iTMmTMHAKBSqRAcHFzv5ejoCHt7ewQHB0OhUEAikWDmzJn473//i23btuHMmTOYNGkSvLy87lgviIjIGNwcVPh+6gB4O1rjcl4pnvv6GApKq8Qu6w7xGddRVF4NtbUVevk6Nvn7tWsC1a4M/UscZ4OReRF1EDQAjB8/HteuXcPcuXORnZ2NXr16YceOHfpBzOnp6ZBKm5bT3nzzTZSWlmLatGkoLCzE4MGDsWPHDqhUje/fJiJqCW9Ha/wwNQxPrYjGxZwS9Ht/D+yUctgp5bBX1f5fO9XNn+1VVvrPHW2sMKSzK1ztlUatsa77a2gXV8hlzfv38BO9vfHxzgs4nnodqXml8HexNWSJREYjEQSB8xdvo9FooFarUVRUxPFARNQiSbkleH5VDK42Ys+xW8mlEozo5obx/XwxtHPzA8q9PLb0IM5larDoqRCMuzGepzmeXxWDAxev4f8e7IR/PBxowAqJmqYpv79FbwEiImrLOrnZ4cAbw5BfWoXiihqUVNagpKIGJZXVKK6oufle5c0/p+aV4szVIuw8l4Od53Lg7qDEk6E+eKqvL/zaGaaFJUdTgXOZGkgkwANdmj4A+lZPhvrgwMVr+CX2Cl6P6HLftZOIWgMGICIiI5PLpHB3UMG9CQ3KidnF2Hg8A5tPXkGOphLL9iVj2b5khAe0w/h+vhgZ7NHg6tSNtf/G4ochPo5oZ9eyrraHgtxhr5Ijs6gC0ZfzMagT1wSi1k/0QdBERHSnQA97zB0VhKP/GoHPn+2NIZ1dIJEA0ZfzMXNjPPq/vwdzt55t9tYb+unvzZj9dTuVlQyjQ2rXBFp9OBUcWUHmgAGIiKgVU8pleLynF759MQwH3xyOmRGd4e1oDU1FDdZFp+Hxzw7hL18eQVJu47ffqKrR4VBSHoDmrf/TkGfD2kMqAfYk5GDZviSDnJPImBiAiIjMhI+TDWZGdMGfbw7Huhf647GenlDIpIhNu47Hlh7C6sMp0DViX64TaQUoqayBi50CwV5qg9TW3UuNd0d3BwB8susifj2VaZDzEhkLAxARkZmRSSUY2sUVy57tgz/fHI6hXVxRWaPDu7+ex8RVx5B5nxln+xNru78e6OJm0AHLE8P98eLgDgCAf/x0CrFpBQY7N5GhMQAREZkxD7UKa6f0w3tjukNlJcXhpHxELv4TW05evetYnH0Xbuz+bqDur1v969FuiOjmjqoaHaaui0VafqnBr0FkCAxARERmTiKRYGK4P7b/fQhCfB1RXFGDmRvj8eoPJ3H9thWoMwrKcCm3BDKpBEM6Gz4AyaQSLH2mF4K9HVBQWoUpa46jqIz7hFHrwwBERNRGBLja4ZeXwzHroS6QSyX4/UwWIhf/qZ/yDtyc/h7q5wS1tZVR6rBRyPHN8/3gqVbh8rVS/O27E6iq0RnlWkTNxQBERNSGyGVS/H1EZ2x6ZSA6utoit7gSk1cfx7+3nEFZVQ32JRpu+vu9uDuosGpyP9gqZDh6uQD/2nyG0+NFdjGnGJoKtsbVYQAiImqDevo44ve/D8Hkgf4AgO+OpuOxpYdwJNmw09/vpZunAz6f0AdSCfBz7BVOjxfRrnPZiFz8JyI+PYD0/DKxy2kVGICIiNoolZUM74zuju9eDIOnWoWUvFJUVOvgqVYh0N3eJDUMD3TDu2OCAdROj9/G6fEmV1hWhbe3nIUgALnFlXj266PIKmra3nRtEQMQEVEbN7izC3a8NhRjetWu1jw6xAsSien265o4wE8/PX42p8eb3Hu/JeBacSUCXG3h384GV66XY8LXx5BXUil2aaLibvAN4G7wRNRWZRWVw91eZfINS7U6AS9/F4vd53PgbKvA5lcGGmxjV7q7fYm5mLL6OCQS4OeXB8LdQYmnlkcjs6gC3TwdsGHqAKhtjDMYXgxN+f3NFiAiIgviqbYWZbd2mVSCJU/3Qg9vNafHm4imohr/2nQGAPDCoA4I9XOCj5MNvnspDC52SiRkaTB5TQxKK2tErlQcDEBERGQSNgo5vn6+L7xumR5fVM4QZCwLticgq6gCfu1sMPvhQP37Aa52+O6l/lBbW+FkeiGmrjuBimqtiJWKgwGIiIhMxt1BhW8m94OdUo6jlwsw+KO9+CzqEkostBXCWA5dysP6mAwAwEd/6Qlrhaze5109HLD2hf6wVchwJDkfM76PQ7XWstZqYgAiIiKT6ubpgNVT+qGLux2KK2rw6e6LGPLRXiw/kIyyKgahliqtrMFbm04DACaF+2FAQLsGj+vl64hvJveDUi5F1IVcvL4xHtpGbKbbVjAAERGRyfXzd8Yfrw3Fkqd7IcDFFtfLqvHhHxcwdOF+rDqUYpFdMoaycMcFXLleDm9Ha/xzZNd7HjsgoB2WTwyFlUyC305n4V+bzkBnISGIs8AawFlgRESmU6PVYUt8JpZEXURGQe36NB4OKrz6YCc81dcXCjn/rd5YMSkFeGpFNADguxfDMLizS6O+98eZLMz4IQ46AZgyyB9zHw8y6VIJhsJZYEREZDbkMimeDPXB3n8MwwdP9ICnWoVsTQX+veUsHvx0P348noEaCxmfUlBa1ex7La/S4s2fTwEAnu7n2+jwAwCP9PDEwidDAACrD6fif7svNqsGc8IWoAawBYiISDwV1VpsiEnHsv3JuFZcu1hfBxdbTB/WEaNDvKCykt3nDOalskaL7WeysPZIGuIzCuHXzgZvjeyKkcEeTWqFef/381h5MAUeDirsmjUUDqqmr++zLjoVc7eeAwDMeaQr/vZAxyafQ0xN+f3NANQABiAiIvGVV2nx3dE0fHkgGQWlVQAAJxsrjO/XHs8NaA8fJxuRK2yZzMJy/HAsHetj0pF/4/5u1dfPCW8/1g292zvd91xx6dfx5JdHoBOAVZP74sGu7s2u64v9SVi4IxEA8N6Y7pgY7t/sc5kaA1ALMQAREbUeJZU1+O5oGr6NTsPVwtoxQlIJMKKbO54P98egTu3MZryKIAg4erkA66JTset8jn7WladahecG+GFUTy/8HJuBrw5eRkV1bVfYqBAvvBkZCF/nhgNfRbUWj392CEm5JRjX2xuLxvdqcZ0f77yAZfuSAQALn+yJp/r6tvicpsAA1EIMQERErY9WJyAqIQfrotNwKClP/35HV1tMCvfHuD7esG9Et0+1VofkayW4kFWMhCwNLmQXw1Otwv+N6AxvR2uj1F5aWYPNJ69iXXQqLuaU6N8fEOCMyQP9EdHNHXLZzWG52UUV+GRXIn6JuwJBABQyKSYP8seM4Z2gtq5/j3VhxcVOiT2zhsLRRtHiegVBwHu/JWDV4RRIJMDi8b0wppd3i88LANdLq7DgjwT869FuBqn1VgxALcQARETUuiXlFuPb6DT8EndVv4iirUKGcX18MCncD51v7HZfUFqFhCwNErI0OJ+lwYWsYiTllqCqgYHGKispXn6gI/42tOMdCwc2V2peKdZGp+LnE1dQfKNOaysZxvXxxqRwfwR62N/z++cyi/DB9gQcTsoHADjaWOG1EZ0xIcwPCrkUZ64UYewXh6HVCVj+XChGBnsYpG6gNgS9veUsfjiWDplUgmXP9mnx+ROyNJj27QlkFJRjZHcPLJ8YaqBqazEAtRADEBGReSiprMHmuCtYG52GpNybLSvdvRxwrbgSucUN73hup5Sjq4c9unk6oLO7HX47nYWYlNpd6r3UKsx5tBse7+nZrK41QRBwIu06Vv55GbsTclD3W7aDiy0mDvDDX0J97mjFud/59idewwfbE3Dpxj12cLHFG5GBWBp1CReyi/F4T098/myfJtd6PzqdgNk/n8KmuKuwkknw1aS+GB7o1qxz/X46C7N/OoXyai3aO9tg5aS+9w2ATcUA1EIMQERE5kUQBEQn52NtdCp2n8/BrWv5+bWzQTcPB3T1rA08QZ4O8HasvymsIAjYfiYbH2xP0I8z6ufvhHmjuiPYW92oGmq0Ouw8l4OVBy8jPqNQ//7wQFdMHtQBQzq5tGgj2hqtDhtPZOB/uy8ir+TmoGlnWwV2vz4U7eyUzT73/a772sZ4/H46C0q5FKsn98PATo2fYq/VCfh0VyK+2F87pmhIZxd89kxvg3d/AQxALcYARERkvq4WluNEagF8nGwQ6GEPO6W80d8tr9Liqz8v48sDSaio1kEiAcb39cXsyEC43CVglFbW4McTGfjmUAquXK8NTwq5FH/p440XB3dAJzfDtnKUVNZg+f5krDx4GZU1Onz2TG+MCvEy6DVuV63V4ZXv47D7fA6srWT49sX+6OvvfN/vFZVX47UNJ7E/8RoA4G9DA/BGZGC98U6GxADUQgxARESWLbOwHB/+cQHbTmUCAOyVcrwW0RmTwv31K1NnF1VgzZFU/HAsDZqK2vE9TjZWmBjuj4kD/OBqb5wWmTq5mgrkFlc2uoWqpSprtJi6LhZ/XrwGO6Uc378UhhBfx7sefymnGNO+jUVKXilUVlJ89JeeBhtIfTcMQC3EAERERABwPLUA72w7h3OZGgBAgIstZgzvhMPJefj1VCaqtbW/Qju42OLFwR3wlz4+BhtA3RqVV2kxZU0Mjl4ugNraCuunDkCQ152/J3eey8asjfEordLC29EaKyaGmiSoMQC1EAMQERHV0eoE/BybgY93JtYbewPUjhOaOiQAEd3cWzS+x5yUVNZg0jfHEJdeiHa2Cmz82wB9N59OJ2BJ1CUsiboEoHaa/7Jn+xhtfNLtGIBaiAGIiIhup6moxud7k7DxeAYGd3bB1CEB6HWPLqC2rKi8GhO+PoqzVzVws1fix7+Fo52dAq9vPIU9CTkAgMkD/fH2Y91gZaTxPg1hAGohBiAiIqJ7u15ahae/OorEnGJ4O1rDWiFDUm4JFHIp3h8bjL+KsHo0d4MnIiIio3KyVeC7l8IQ4GqLq4XlSMotgbtDbWuQGOGnqRiAiIiIqFlc7ZX44aUB6OXriAe6uOLXVwebTbdg4xdHICIiIrqNh1qFLTMGiV1Gk7EFiIiIiCwOAxARERFZHAYgIiIisjgMQERERGRxGICIiIjI4jAAERERkcVhACIiIiKLwwBEREREFocBiIiIiCwOAxARERFZHAYgIiIisjgMQERERGRxGICIiIjI4jAAERERkcWRi11AayQIAgBAo9GIXAkRERE1Vt3v7brf4/fCANSA4uJiAICvr6/IlRAREVFTFRcXQ61W3/MYidCYmGRhdDodMjMzYW9vD4lEYtBzazQa+Pr6IiMjAw4ODgY9d2thCfcI8D7bGt5n22EJ9wjwPhsiCAKKi4vh5eUFqfTeo3zYAtQAqVQKHx8fo17DwcGhTf8PFrCMewR4n20N77PtsIR7BHift7tfy08dDoImIiIii8MARERERBaHAcjElEol5s2bB6VSKXYpRmMJ9wjwPtsa3mfbYQn3CPA+W4qDoImIiMjisAWIiIiILA4DEBEREVkcBiAiIiKyOAxAREREZHEYgExo2bJl8Pf3h0qlQlhYGGJiYsQuyaDeeecdSCSSeq+uXbuKXVaL/fnnnxg1ahS8vLwgkUiwZcuWep8LgoC5c+fC09MT1tbWiIiIwKVLl8QptgXud5+TJ0++4/mOHDlSnGKbacGCBejXrx/s7e3h5uaGsWPHIjExsd4xFRUVmDFjBtq1awc7Ozv85S9/QU5OjkgVN09j7nPYsGF3PM+XX35ZpIqb58svv0TPnj31C+SFh4fjjz/+0H/eFp4lcP/7bAvP8nYffvghJBIJZs6cqX/P0M+TAchENm7ciFmzZmHevHmIi4tDSEgIIiMjkZubK3ZpBtW9e3dkZWXpX4cOHRK7pBYrLS1FSEgIli1b1uDnCxcuxNKlS7F8+XIcO3YMtra2iIyMREVFhYkrbZn73ScAjBw5st7zXb9+vQkrbLkDBw5gxowZOHr0KHbv3o3q6mo8/PDDKC0t1R/z+uuv49dff8VPP/2EAwcOIDMzE+PGjROx6qZrzH0CwNSpU+s9z4ULF4pUcfP4+Pjgww8/RGxsLE6cOIEHH3wQY8aMwblz5wC0jWcJ3P8+AfN/lrc6fvw4VqxYgZ49e9Z73+DPUyCT6N+/vzBjxgz9z1qtVvDy8hIWLFggYlWGNW/ePCEkJETsMowKgLB582b9zzqdTvDw8BA+/vhj/XuFhYWCUqkU1q9fL0KFhnH7fQqCIDz//PPCmDFjRKnHWHJzcwUAwoEDBwRBqH12VlZWwk8//aQ/JiEhQQAgREdHi1Vmi91+n4IgCA888IDw2muviVeUkTg5OQlff/11m32WderuUxDa1rMsLi4WOnfuLOzevbvefRnjebIFyASqqqoQGxuLiIgI/XtSqRQRERGIjo4WsTLDu3TpEry8vBAQEIAJEyYgPT1d7JKMKiUlBdnZ2fWerVqtRlhYWJt7tgCwf/9+uLm5ITAwENOnT0d+fr7YJbVIUVERAMDZ2RkAEBsbi+rq6nrPs2vXrmjfvr1ZP8/b77PO999/DxcXFwQHB2POnDkoKysTozyD0Gq12LBhA0pLSxEeHt5mn+Xt91mnrTzLGTNm4LHHHqv33ADj/LfJzVBNIC8vD1qtFu7u7vXed3d3x4ULF0SqyvDCwsKwZs0aBAYGIisrC++++y6GDBmCs2fPwt7eXuzyjCI7OxsAGny2dZ+1FSNHjsS4cePQoUMHJCcn41//+hceeeQRREdHQyaTiV1ek+l0OsycORODBg1CcHAwgNrnqVAo4OjoWO9Yc36eDd0nADz77LPw8/ODl5cXTp8+jX/+859ITEzEpk2bRKy26c6cOYPw8HBUVFTAzs4OmzdvRlBQEOLj49vUs7zbfQJt51lu2LABcXFxOH78+B2fGeO/TQYgMphHHnlE/+eePXsiLCwMfn5++PHHH/Hiiy+KWBkZwtNPP63/c48ePdCzZ0907NgR+/fvx4gRI0SsrHlmzJiBs2fPtolxavdyt/ucNm2a/s89evSAp6cnRowYgeTkZHTs2NHUZTZbYGAg4uPjUVRUhJ9//hnPP/88Dhw4IHZZBne3+wwKCmoTzzIjIwOvvfYadu/eDZVKZZJrsgvMBFxcXCCTye4YrZ6TkwMPDw+RqjI+R0dHdOnSBUlJSWKXYjR1z8/Sni0ABAQEwMXFxSyf76uvvorffvsN+/btg4+Pj/59Dw8PVFVVobCwsN7x5vo873afDQkLCwMAs3ueCoUCnTp1QmhoKBYsWICQkBAsWbKkzT3Lu91nQ8zxWcbGxiI3Nxd9+vSBXC6HXC7HgQMHsHTpUsjlcri7uxv8eTIAmYBCoUBoaCiioqL07+l0OkRFRdXrw21rSkpKkJycDE9PT7FLMZoOHTrAw8Oj3rPVaDQ4duxYm362AHDlyhXk5+eb1fMVBAGvvvoqNm/ejL1796JDhw71Pg8NDYWVlVW955mYmIj09HSzep73u8+GxMfHA4BZPc+G6HQ6VFZWtplneTd199kQc3yWI0aMwJkzZxAfH69/9e3bFxMmTND/2eDPs+VjtqkxNmzYICiVSmHNmjXC+fPnhWnTpgmOjo5Cdna22KUZzD/+8Q9h//79QkpKinD48GEhIiJCcHFxEXJzc8UurUWKi4uFkydPCidPnhQACIsWLRJOnjwppKWlCYIgCB9++KHg6OgobN26VTh9+rQwZswYoUOHDkJ5ebnIlTfNve6zuLhYmD17thAdHS2kpKQIe/bsEfr06SN07txZqKioELv0Rps+fbqgVquF/fv3C1lZWfpXWVmZ/piXX35ZaN++vbB3717hxIkTQnh4uBAeHi5i1U13v/tMSkoS5s+fL5w4cUJISUkRtm7dKgQEBAhDhw4VufKmeeutt4QDBw4IKSkpwunTp4W33npLkEgkwq5duwRBaBvPUhDufZ9t5Vk25PbZbYZ+ngxAJvTZZ58J7du3FxQKhdC/f3/h6NGjYpdkUOPHjxc8PT0FhUIheHt7C+PHjxeSkpLELqvF9u3bJwC44/X8888LglA7Ff4///mP4O7uLiiVSmHEiBFCYmKiuEU3w73us6ysTHj44YcFV1dXwcrKSvDz8xOmTp1qdgG+ofsDIKxevVp/THl5ufDKK68ITk5Ogo2NjfDEE08IWVlZ4hXdDPe7z/T0dGHo0KGCs7OzoFQqhU6dOglvvPGGUFRUJG7hTfTCCy8Ifn5+gkKhEFxdXYURI0bow48gtI1nKQj3vs+28iwbcnsAMvTzlAiCIDSv7YiIiIjIPHEMEBEREVkcBiAiIiKyOAxAREREZHEYgIiIiMjiMAARERGRxWEAIiIiIovDAEREREQWhwGIiIiILA4DEBFRA/z9/bF48WKxyyAiI2EAIiLRTZ48GWPHjgUADBs2DDNnzjTZtdesWQNHR8c73j9+/DimTZtmsjqIyLTkYhdARGQMVVVVUCgUzf6+q6urAashotaGLUBE1GpMnjwZBw4cwJIlSyCRSCCRSJCamgoAOHv2LB555BHY2dnB3d0dEydORF5env67w4YNw6uvvoqZM2fCxcUFkZGRAIBFixahR48esLW1ha+vL1555RWUlJQAAPbv348pU6agqKhIf7133nkHwJ1dYOnp6RgzZgzs7Ozg4OCAp556Cjk5OfrP33nnHfTq1Qvffvst/P39oVar8fTTT6O4uNi4f2lE1CwMQETUaixZsgTh4eGYOnUqsrKykJWVBV9fXxQWFuLBBx9E7969ceLECezYsQM5OTl46qmn6n1/7dq1UCgUOHz4MJYvXw4AkEqlWLp0Kc6dO4e1a9di7969ePPNNwEAAwcOxOLFi+Hg4KC/3uzZs++oS6fTYcyYMSgoKMCBAwewe/duXL58GePHj693XHJyMrZs2YLffvsNv/32Gw4cOIAPP/zQSH9bRNQS7AIjolZDrVZDoVDAxsYGHh4e+vc///xz9O7dGx988IH+vVWrVsHX1xcXL15Ely5dAACdO3fGwoUL653z1vFE/v7++O9//4uXX34ZX3zxBRQKBdRqNSQSSb3r3S4qKgpnzpxBSkoKfH19AQDr1q1D9+7dcfz4cfTr1w9AbVBas2YN7O3tAQATJ05EVFQU3n///Zb9xRCRwbEFiIhavVOnTmHfvn2ws7PTv7p27QqgttWlTmho6B3f3bNnD0aMGAFvb2/Y29tj4sSJyM/PR1lZWaOvn5CQAF9fX334AYCgoCA4OjoiISFB/56/v78+/ACAp6cncnNzm3SvRGQabAEiolavpKQEo0aNwkcffXTHZ56envo/29ra1vssNTUVjz/+OKZPn473338fzs7OOHToEF588UVUVVXBxsbGoHVaWVnV+1kikUCn0xn0GkRkGAxARNSqKBQKaLXaeu/16dMHv/zyC/z9/SGXN/7/bcXGxkKn0+HTTz+FVFrb4P3jjz/e93q369atGzIyMpCRkaFvBTp//jwKCwsRFBTU6HqIqPVgFxgRtSr+/v44duwYUlNTkZeXB51OhxkzZqCgoADPPPMMjh8/juTkZOzcuRNTpky5Z3jp1KkTqqur8dlnn+Hy5cv49ttv9YOjb71eSUkJoqKikJeX12DXWEREBHr06IEJEyYgLi4OMTExmDRpEh544AH07dvX4H8HRGR8DEBE1KrMnj0bMpkMQUFBcHV1RXp6Ory8vHD48GFotVo8/PDD6NGjB2bOnAlHR0d9y05DQkJCsGjRInz00UcIDg7G999/jwULFtQ7ZuDAgXj55Zcxfvx4uLq63jGIGqjtytq6dSucnJwwdOhQREREICAgABs3bjT4/RORaUgEQRDELoKIiIjIlNgCRERERBaHAYiIiIgsDgMQERERWRwGICIiIrI4DEBERERkcRiAiIiIyOIwABEREZHFYQAiIiIii8MARERERBaHAYiIiIgsDgMQERERWZz/B5xIFcY8g+oTAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TRAINING\n",
    "iter_loss = []\n",
    "epoch_loss = []\n",
    "best_acc = 0\n",
    "\n",
    "for t in range(EPOCHS):\n",
    "    print(f'Epoch {t} starts.')\n",
    "    tloss = train(trainloader, valloader, model, OPTIMIZER, SCHEDULER, LOSS_FN, 50)\n",
    "    val_loss, val_acc = test(valloader, model, LOSS_FN)\n",
    "    \n",
    "    iter_loss = iter_loss + tloss\n",
    "    epoch_loss.append(sum(tloss) / len(tloss))\n",
    "    \n",
    "    print(f'Epoch {t}: LOSS = {epoch_loss[-1]}, VAL-ACC = {val_acc}')\n",
    "    \n",
    "torch.save(model.state_dict(), f'HAN_last.pth')\n",
    "    \n",
    "fig, axes = plt.subplots()\n",
    "axes.plot(epoch_loss, label = 'train-loss')\n",
    "axes.legend()\n",
    "axes.set_xlabel('Iteration')\n",
    "axes.set_ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2fc977ad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-03T02:34:07.860341Z",
     "iopub.status.busy": "2024-06-03T02:34:07.860048Z",
     "iopub.status.idle": "2024-06-03T02:34:10.036190Z",
     "shell.execute_reply": "2024-06-03T02:34:10.034897Z"
    },
    "papermill": {
     "duration": 2.204552,
     "end_time": "2024-06-03T02:34:10.039413",
     "exception": false,
     "start_time": "2024-06-03T02:34:07.834861",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(LAST) Test accuracy: 0.7806935332708529\n"
     ]
    }
   ],
   "source": [
    "_, val_acc = test(testloader, model, LOSS_FN)\n",
    "print(f'(LAST) Test accuracy: {val_acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3bd2ca9b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-03T02:34:10.096140Z",
     "iopub.status.busy": "2024-06-03T02:34:10.095213Z",
     "iopub.status.idle": "2024-06-03T02:34:12.243521Z",
     "shell.execute_reply": "2024-06-03T02:34:12.242448Z"
    },
    "papermill": {
     "duration": 2.178691,
     "end_time": "2024-06-03T02:34:12.245643",
     "exception": false,
     "start_time": "2024-06-03T02:34:10.066952",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(BEST) Test accuracy: 0.7525773195876289\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('HAN_best.pth', map_location= DEVICE))\n",
    "_, val_acc = test(testloader, model, LOSS_FN)\n",
    "print(f'(BEST) Test accuracy: {val_acc}')"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 1835,
     "sourceId": 3176,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 10100,
     "sourceId": 3316532,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 2546760,
     "sourceId": 4345109,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4741673,
     "sourceId": 8053014,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5093015,
     "sourceId": 8528311,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30673,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1947.230451,
   "end_time": "2024-06-03T02:34:15.496082",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-06-03T02:01:48.265631",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
